<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Payam Emami">

<title>Multi-Omics Factor Analysis (MOFA)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="mofa_files/libs/clipboard/clipboard.min.js"></script>
<script src="mofa_files/libs/quarto-html/quarto.js"></script>
<script src="mofa_files/libs/quarto-html/popper.min.js"></script>
<script src="mofa_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="mofa_files/libs/quarto-html/anchor.min.js"></script>
<link href="mofa_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="mofa_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="mofa_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="mofa_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="mofa_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Multi-Omics Factor Analysis (MOFA)</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Payam Emami </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In classical data integration, we would like to use information across different modalities (eg., transcriptome, proteome and metabolome) to gain more comprehensive insights into the biological systems under study. This type of data can be used for an array of different purposes including but not limited to molecular classification, stratification of patients, outcome predictions and understanding of regulatory processes such as gene regulation and pathway analysis.</p>
<p>In this specific context, we are going to focus on unsupervised modeling and segmentation, which are promising because each type of omics data may contribute valuable information to the overall understanding of complex biological systems. By leveraging unsupervised modeling, we can uncover hidden patterns and relationships within the data without relying on predefined labels. This is especially beneficial when dealing with omics data, where the volume and complexity can be overwhelming. Furthermore, segmentation allows us to group similar data points, making it easier to identify and analyze specific subsets of the data. Given the heterogeneous nature of omics data, integrating multiple types can provide a more comprehensive view of the underlying biological processes.</p>
<p>In this lab we are going to learn the basics of how Multi-Omics Factor Analysis (MOFA) uses multiple data views to uncover hidden but common pattern within the data. Before start using MOFA we are going to learn a few background concepts to understand and appreciate how this technique works. Let’s start with typical PCA.</p>
</section>
<section id="pca" class="level1">
<h1>PCA</h1>
<p>PCA is a special case of SVD in which basis vectors, or principal components, are the eigenvectors of the data’s covariance matrix. These principal components are orthogonal and represent the directions of maximum variance in the data. If you want to know more about PCA look at <a href="http://payamemami.com/pca_basics/" title="PCA basics">here</a>.</p>
<p>Principal Component Analysis (PCA) might sound complex at first, but it can be understood intuitively as a method for simplifying and summarizing complex, multidimensional data.</p>
<p>Given a dataset containing the expression levels of thousands of genes from a group of individuals. Each individual is a complex data sample characterized by the expression of all these genes. Visualizing or analyzing such high-dimensional data can be very difficult.</p>
<p>PCA simplifies this complex, multidimensional space by identifying the “principal components” of the data, which are new axes that capture the most significant patterns in the data. These axes are combinations of the original gene expression levels that explain the maximum variance in the dataset.</p>
<p>For example, the first principal component (PC) might represent a combination of genes that change the most across all individuals. It could capture a general trend in gene expression that separates individuals based on age or response to a treatment. The second PC (orthogonal to the first), might capture the next highest variance, showing another layer of structure in the data, and so on.</p>
<p>Formally,PCA is derived from the right singular vectors contained in matrix <span class="math inline">\(V\)</span>. The singular values in <span class="math inline">\(\Sigma\)</span> are related to the eigenvalues of the covariance matrix of the original data, and they indicate the amount of variance captured by each principal component.</p>
<p>In simpler terms, when we perform SVD on a data matrix <span class="math inline">\(A\)</span>, the columns of <span class="math inline">\(V\)</span> (the right singular vectors) are actually the principal components of <span class="math inline">\(A\)</span>. The singular values in <span class="math inline">\(\Sigma\)</span> tell us the importance or weight of these principal components.</p>
<p>The SVD of a matrix <span class="math inline">\(A \in \mathbb{R}^{m \times n}\)</span> is expressed as: <span class="math display">\[
A = U \Sigma V^T
\]</span> where</p>
<p>- <span class="math inline">\(U \in \mathbb{R}^{m \times m}\)</span> is the left singular matrix,</p>
<p>- <span class="math inline">\(\Sigma \in \mathbb{R}^{m \times n}\)</span> is the diagonal matrix containing the singular values, and</p>
<p>- <span class="math inline">\(V \in \mathbb{R}^{n \times n}\)</span> is the right singular matrix.</p>
<p>To see this connection clearly, let’s consider the covariance matrix of <span class="math inline">\(A\)</span>, denoted as <span class="math inline">\(C\)</span>: <span class="math display">\[
C = \frac{1}{n-1} A^T A
\]</span></p>
<p>When we perform eigen decomposition on <span class="math inline">\(C\)</span>, we get: <span class="math display">\[
C = W \Lambda W^T
\]</span> where <span class="math inline">\(W\)</span> contains the eigenvectors and <span class="math inline">\(\Lambda\)</span> is a diagonal matrix containing the eigenvalues.</p>
<p>Now, if we look at the SVD of <span class="math inline">\(A\)</span> again: <span class="math display">\[
A = U \Sigma V^T
\]</span> and compute <span class="math inline">\(A^T A\)</span>, we get: <span class="math display">\[
A^T A = V \Sigma^T U^T U \Sigma V^T = V \Sigma^2 V^T
\]</span></p>
<p>Comparing this with the eigen decomposition of <span class="math inline">\(C\)</span>, we observe that the right singular vectors <span class="math inline">\(V\)</span> are the eigenvectors of <span class="math inline">\(C\)</span>, and the singular values squared in <span class="math inline">\(\Sigma^2\)</span> are the eigenvalues in <span class="math inline">\(\Lambda\)</span>.</p>
<section id="section" class="level4">
<h4 class="anchored" data-anchor-id="section"></h4>
<p>There are other algorithms for doing PCA for example using power methods but almost all of them will converge to the same solution with a certain numerical accuracy.</p>
</section>
<section id="pca-in-practice" class="level2">
<h2 class="anchored" data-anchor-id="pca-in-practice">PCA in practice</h2>
<section id="data" class="level3">
<h3 class="anchored" data-anchor-id="data">Data</h3>
<p>Our data has to be in a data.frame where features are in the columns and samples in the rows. For now we are going to use TCGA dataset from mixOmics.</p>
<blockquote class="blockquote">
<p><em>This data set is a small subset of the full data set from The Cancer Genome Atlas that can be analysed with the DIABLO framework. It contains the expression or abundance of three matching omics data sets: mRNA, miRNA and proteomics for 150 breast cancer samples (Basal, Her2, Luminal A) in the training set, and 70 samples in the test set. The test set is missing the proteomics data set.</em></p>
</blockquote>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-1_9de290ed73e7c2f163ceb3f1dfcb490b">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the dataset</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(<span class="st">"https://github.com/mixOmicsTeam/mixOmics/raw/master/data/breast.TCGA.rda"</span>, <span class="at">destfile =</span> <span class="st">"TCGA.rda"</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># load the data</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"TCGA.rda"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This data has already been split into a list with two elements. Training and testing. Each element itself is a list of four elements. Three elements are the actual datasets and one is the cancer subtypes.</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-2_1da6f5fe2a50adea794249154fd6e454">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(breast.TCGA)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>List of 2
 $ data.train:List of 4
  ..$ mirna  : num [1:150, 1:184] 11.8 12.9 12.3 12 13.4 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:150] "A0FJ" "A13E" "A0G0" "A0SX" ...
  .. .. ..$ : chr [1:184] "hsa-let-7a-1" "hsa-let-7a-2" "hsa-let-7a-3" "hsa-let-7b" ...
  ..$ mrna   : num [1:150, 1:200] 4.36 1.98 1.73 4.36 2.45 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:150] "A0FJ" "A13E" "A0G0" "A0SX" ...
  .. .. ..$ : chr [1:200] "RTN2" "NDRG2" "CCDC113" "FAM63A" ...
  ..$ protein: num [1:150, 1:142] 0.0491 -0.08 -0.0328 -0.2053 0.0602 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:150] "A0FJ" "A13E" "A0G0" "A0SX" ...
  .. .. ..$ : chr [1:142] "14-3-3_epsilon" "4E-BP1" "4E-BP1_pS65" "4E-BP1_pT37" ...
  ..$ subtype: Factor w/ 3 levels "Basal","Her2",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ data.test :List of 3
  ..$ mirna  : num [1:70, 1:184] 12.8 13.9 12.9 12.4 13.1 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:70] "A54N" "A2NL" "A6VY" "A3XT" ...
  .. .. ..$ : chr [1:184] "hsa-let-7a-1" "hsa-let-7a-2" "hsa-let-7a-3" "hsa-let-7b" ...
  ..$ mrna   : num [1:70, 1:200] 1.19 2.73 3.05 2.7 3.14 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:70] "A54N" "A2NL" "A6VY" "A3XT" ...
  .. .. ..$ : chr [1:200] "RTN2" "NDRG2" "CCDC113" "FAM63A" ...
  ..$ subtype: Factor w/ 3 levels "Basal","Her2",..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
</div>
</div>
</section>
<section id="pca-in-r" class="level3">
<h3 class="anchored" data-anchor-id="pca-in-r">PCA in R</h3>
<p>Doing PCA in R using SVD is straight forward. We should just center our data and use the <code>svd</code> function.</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-3_6eb5e3a704963cc54a5e0b2a8643c04a">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># center the data</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>data_centered_mrna <span class="ot">&lt;-</span> <span class="fu">scale</span>(breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>mrna,<span class="at">center =</span> <span class="cn">TRUE</span>,<span class="at">scale =</span> <span class="cn">FALSE</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># do SVD</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>svd_mrna <span class="ot">&lt;-</span> <span class="fu">svd</span>(data_centered_mrna)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the PC scores</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>calculated_scores <span class="ot">&lt;-</span> data_centered_mrna<span class="sc">%*%</span>svd_mrna<span class="sc">$</span>v</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the PC scores</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(calculated_scores[,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],<span class="at">xlab=</span><span class="st">"pc1"</span>,<span class="at">ylab=</span><span class="st">"pc2"</span>,<span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This will give us identical results comapred to the for example standard <code>prcomp</code> function</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-4_81334099fcee39495a63ab98be498c81">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># do pca using prcomp</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>pca_prcomp <span class="ot">&lt;-</span> <span class="fu">prcomp</span>(data_centered_mrna)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the PCA</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(pca_prcomp<span class="sc">$</span>x[,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>],<span class="at">xlab=</span><span class="st">"pc1"</span>,<span class="at">ylab=</span><span class="st">"pc2"</span>,<span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>In practice there are more specialized packages that can be used to do PCA. <code>mixOmics</code> provides a very powerful PCA method that provide us not only with standard PCA but also with extra advantange (eg., missing value handling, plotting, handling repeated measurements etc).</p>
<p>This observed separation and overlap in the PCA plot is not just a graphical representation but is rooted in the underlying biology of these cancer subtypes. The positioning of the different groups on the PCA plot is influenced by the expression levels of various mRNAs, each contributing differently to the principal components.</p>
<p>Now, as we go deeper into understanding the PCA plot, it becomes essential to explore the concept of <code>loadings</code>. Loadings help us interpret the contribution of each miRNA to the principal components. They provide insights into which specific miRNAs are driving the separation between different cancer subtypes observed in the PCA plot.</p>
<p>We can go ahead and plot the loadings. We start with our most important PC, that is PC1</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-5_3165e754f28c4f502f841328cb3d594a">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># loadings for component 1</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>loadings <span class="ot">&lt;-</span> pca_prcomp<span class="sc">$</span>rotation[,<span class="dv">1</span>]</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort the loadings</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>sorted_loadings <span class="ot">&lt;-</span> loadings[<span class="fu">order</span>(<span class="fu">abs</span>(loadings),<span class="at">decreasing =</span> T)]</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the loadings in a flipped barplot</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="fu">barplot</span>(sorted_loadings, <span class="at">horiz=</span><span class="cn">TRUE</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">main=</span><span class="st">"PCA Loadings"</span>, <span class="at">xlab=</span><span class="st">"Loadings"</span>, <span class="at">border=</span><span class="st">"blue"</span>, <span class="at">col=</span><span class="st">"skyblue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>In this bar plot, each bar represents a specific mRNA. The length of the bar corresponds to the value of the loading of that mRNA on PC1, indicating its contribution to this principal component. The mRNAs with the highest absolute contributions are at the bottom, and those with the lowest are at the top, making it easy to identify the most influential mRNAs. Both the length and direction of each bar provide crucial insights into the mRNA’s contribution to the first principal component (PC1). The length of the bar signifies the magnitude of the mRNA’s contribution. Longer bars indicate miRNAs that have a more substantial influence on the variance captured by PC1, highlighting them as key elements in distinguishing different patterns of gene expression within the dataset.</p>
<p>The direction of the bars adds another layer of interpretation. Bars extending to the right represent mRNAs that are positively correlated with PC1, indicating that as the values of these mRNAs increase, so does the score of PC1. Conversely, bars extending to the left suggest a negative correlation, meaning as the values of these miRNAs increase, the score of PC1 decreases. This directional information can be important in understanding the expression patterns of mRNAs in different breast cancer subtypes. For instance, mRNAs that are positively correlated with PC1 might be highly expressed in the Basal subtype but low in others, offering insights into the molecular distinctions between these cancer subtypes.</p>
<p>Score plot together with loading give us powerful tool to investiage pattern in a single dataset.</p>
</section>
</section>
<section id="probabilistic-principal-component-analysis-ppca" class="level2">
<h2 class="anchored" data-anchor-id="probabilistic-principal-component-analysis-ppca">Probabilistic Principal Component Analysis (PPCA)</h2>
<p>After understanding the foundation of PCA, it’s time to explore its probabilistic counterpart, Probabilistic Principal Component Analysis (PPCA). While PCA provides us with a deterministic approach to do data reduction and feature extraction, PPCA introduces a probabilistic framework that models the uncertainties in the data. This transition from a deterministic method to a more flexible, probabilistic one allows for a more systematic understanding of data structures, especially when there’s noise or missing values.</p>
<p>In PPCA, the relationship between the observed data vector $Y $in <span class="math inline">\(\mathbb{R}^{D}\)</span> and the latent or principal component coordinates <span class="math inline">\(Z\)</span> in <span class="math inline">\(\mathbb{R}^{d}\)</span> is expressed by:</p>
<p><span class="math display">\[X = ZW^T + \epsilon\]</span></p>
<p>Where <span class="math inline">\(X\)</span> is the observed data vector. <span class="math inline">\(Z\)</span> represents the latent variables or the principal component coordinates. <span class="math inline">\(W\)</span> is a matrix of size <span class="math inline">\(d \times D\)</span> that defines the linear relationship between <span class="math inline">\(Z\)</span> and <span class="math inline">\(Y\)</span>. <span class="math inline">\(\epsilon\)</span> is a Gaussian noise term, which accounts for the variability not captured by the principal components.</p>
<p>Given our equation, we start with a prior on the latent variables, <span class="math inline">\(Z\)</span>, assuming they are drawn from a standard Gaussian distribution: <span class="math display">\[ p(Z) = N(Z; 0, I) \]</span> This means that the principal component coordinates have a mean of zero and an identity covariance matrix.</p>
<p>Given the linear relationship <span class="math inline">\(Y = ZW^T + \epsilon\)</span>, the conditional distribution of <span class="math inline">\(X\)</span> given <span class="math inline">\(Z\)</span> is <span class="math inline">\(p(X|Z) = N(X; ZW^T, \sigma^2 I)\)</span> This equation suggests that the observed data <span class="math inline">\(X\)</span> is normally distributed around the value produced by projecting <span class="math inline">\(Z\)</span> onto the data space using <span class="math inline">\(W^T\)</span>, with a variance of <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Remembre now our observed data is <span class="math inline">\(X\)</span> but what we are interested in is <span class="math inline">\(Z\)</span> so we need to calculate <span class="math display">\[ p(Z|X)\]</span>. Therefore using the Bayes’ rule for Gaussian distributions:</p>
<p><span class="math display">\[p(z|x) = \frac{p(x|z) \cdot p(z)}{p(x)}\]</span> We don’t need the denominator <span class="math inline">\(p(x)\)</span> explicitly as it’s a normalization constant.</p>
<p><span class="math display">\[ p(z|x) \propto p(x|z) \cdot p(z) \]</span> In the above equation <span class="math inline">\(p(z|x)\)</span> is normally distributed thus</p>
<p><span class="math display">\[
p(z|x)=N(z,\mu,\Sigma)
\]</span></p>
<p>It can be shown that</p>
<p><span class="math display">\[
\mu=\sigma^{-2}\Sigma Wx
\]</span> and <span class="math display">\[
\Sigma^{-1}=I+\sigma^{-2}CC^T
\]</span></p>
<p>To estimate the model parameters, namely <span class="math inline">\(W\)</span> and <span class="math inline">\(\sigma^2\)</span>, we employ the Expectation-Maximization (EM) algorithm. This iterative algorithm seeks to maximize the likelihood of observing the data <span class="math inline">\(x\)</span> given the model parameters.</p>
<p>The EM algorithm consists of two main steps:</p>
<ul>
<li><p><strong>E-Step</strong>: Here, we estimate the distribution of the latent variable <span class="math inline">\(z\)</span> given the observed data <span class="math inline">\(x\)</span> and the current estimate of the model parameters.</p></li>
<li><p><strong>M-Step</strong>: In this step, we update the model parameters <span class="math inline">\(W\)</span> and <span class="math inline">\(\sigma^2\)</span> to maximize the expected complete-data log-likelihood.</p></li>
</ul>
<p>One challenge in directly maximizing the log-likelihood <span class="math inline">\(log p(x)\)</span> (which quantifies how well our model describes the observed data) is its complexity due to the latent variable <span class="math inline">\(z\)</span>. To fix this, we introduce a distribution <span class="math inline">\(q(z)\)</span> over <span class="math inline">\(z\)</span> and derive a lower bound on the log-likelihood. This lower bound is defined as:</p>
<p><span class="math display">\[log p(x) \geq H(q(z)) + E_q[log p(z) + log p(x|z)]\]</span></p>
<p>Where <span class="math inline">\(H(q(z))\)</span> is the entropy of <span class="math inline">\(q(z)\)</span>, and <span class="math inline">\(E_q[.]\)</span> is the expectation under the distribution <span class="math inline">\(q\)</span>.</p>
<p>Derivation of the lower bound involves KL: <span class="math display">\[
log p(x) = log p(x) - D(q(z) || p(z|x)) + D(q(z) || p(z|x))
\]</span> Expanding using properties of KL divergence <span class="math display">\[
log p(x) = H(q(z)) + E_q[log p(x, z) - log q(z)]
\]</span> and finally decomposing the joint likelihood <span class="math inline">\(log p(x, z)\)</span> into <span class="math inline">\(log p(z) + log p(x|z)\)</span>).</p>
<p><span class="math display">\[
log p(x) ≥ H(q(z)) + E_q[log p(z) + log p(x|z)]
\]</span></p>
<p>Given the likelyhood function we can now derive our E and M steps of EM.</p>
<p>We can simply look at what we derived for <span class="math inline">\(p(z|x)\)</span> which was: <span class="math display">\[
\mu=\sigma^{-2}\Sigma Wx
\]</span> and <span class="math display">\[
\Sigma^{-1}=I+\sigma^{-2}CC^T
\]</span></p>
<p>We can just replace the values to get to expected value of <span class="math inline">\(Z\)</span></p>
<p><span class="math display">\[
Z=\sigma^{-2}(I+\sigma^{-2}CC^T)^{-1} Wx
\]</span></p>
<p>We have <span class="math inline">\(N\)</span> data points so we need to sum over them so, we have: <span class="math display">\[\sum_{n=1}^{N} log p(x_n) \geq \sum_{n=1}^{N} \left( H(q(z_n)) + E_{q(z_n)}[log p(z_n) + log p(x_n|z_n)] \right)\]</span></p>
<p>Expanding the expectation term for <span class="math inline">\(N\)</span> data points and using the Gaussian distributions, we get: <span class="math display">\[\sum_{n=1}^{N} E_{q(z_n)}[log p(z_n) + log p(x_n|z_n)] = \]</span> <span class="math display">\[ - \frac{1}{2\sigma^2} \sum_{n=1}^{N} \left( \lVert x_n - W^⊤z_n \rVert^2 + \text{Tr}{W^⊤Σ_nW} \right) - \frac{1}{2\sigma^2_{\text{old}}} \sum_{n=1}^{N} \lVert z_n \rVert^2 - \frac{N}{2} \text{Tr}{Σ_n} \]</span></p>
<p>where <span class="math inline">\(x_n\)</span> is the observed data point and <span class="math inline">\(z_n\)</span> is the latent representation of <span class="math inline">\(x_n\)</span>. The equation might seem complex but it has three main parts:</p>
<ul>
<li>The reconstruction error (<span class="math inline">\(\lVert x_n - W^⊤z_n \rVert^2\)</span>), which quantifies how well our model can generate the observed data from the latent variables.</li>
<li>The variance or spread of the latent variables (<span class="math inline">\(\lVert z_n \rVert^2\)</span>).</li>
<li>The term (<span class="math inline">\(\text{Tr}{W^⊤Σ_nW}\)</span>) which captures the total variance explained by the latent variables.</li>
</ul>
<p>To determine the model parameters that maximize this bound, we are going to differentiate with respect to <span class="math inline">\(W\)</span> and <span class="math inline">\(\sigma^2\)</span>. Setting these derivatives to zero and we are almost there!</p>
<p><span class="math display">\[W = \left( \sum_{n=1}^{N} Σ_n + z_n z_n^⊤ \right)^{-1} \sum_{n=1}^{N} z_n x_n^⊤\]</span></p>
<p>and <span class="math display">\[\sigma^2 = \frac{1}{ND} \sum_{n=1}^{N} \left( \lVert x_n - W^⊤z_n \rVert^2 + \text{Tr}{W^⊤Σ_nW} \right)\]</span></p>
<p>Recall our expanded equation for the lower bound on the log-likelihood: <span class="math display">\[\sum_{n=1}^{N} log p(x_n) \geq \sum_{n=1}^{N} \left( H(q(z_n)) + E_{q(z_n)}[log p(z_n) + log p(x_n|z_n)] \right)\]</span></p>
<p>The entropy <span class="math inline">\(H\)</span> of a Gaussian with covariance matrix <span class="math inline">\(Σ\)</span> is: <span class="math display">\[H = \frac{1}{2} log |Σ|\]</span></p>
<p>Putting this into our equation, we obtain: <span class="math display">\[\sum_{n=1}^{N} log p(x_n) \geq \sum_{n=1}^{N} \left( \frac{1}{2} log |Σ| + E_{q(z_n)}[log p(z_n) + log p(x_n|z_n)] \right)\]</span></p>
<p>We can further expand the right-hand side: <span class="math display">\[log p(x) \geq -ND\left(1 + log \sigma^2\right) - N\left(Tr\{Σ\} - log |Σ|\right) - \frac{1}{2\sigma^2_{\text{old}}} \sum_{n=1}^{N} \lVert z_n \rVert^2\]</span></p>
<p>Here: <span class="math inline">\(N\)</span> represents the number of data points. <span class="math inline">\(D\)</span> is the dimension of the data vector $ x_n $.</p>
<p>This equation represents the EM bound after performing the M-step. The objective in the M-step of the EM algorithm is to maximize this bound with respect to the model parameters <span class="math inline">\(W\)</span> and <span class="math inline">\(\sigma^2\)</span>. By doing so, we iteratively refine our model to better fit the observed data.</p>
<p>Let’s try to implement it:</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-6_3aeb2b17a02cf9e9f3813338b94c9bb4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the breast cancer dataset for training</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>input_data <span class="ot">&lt;-</span> breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>mrna</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the number of data points (samples) and the dimensionality of the data (genes/features)</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>N_data <span class="ot">&lt;-</span> <span class="fu">nrow</span>(input_data)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>D_data <span class="ot">&lt;-</span> <span class="fu">ncol</span>(input_data)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the number of principal components to be extracted</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>nPcs <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the convergence threshold and maximum number of iterations for the EM algorithm</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>threshold <span class="ot">&lt;-</span> <span class="fl">0.0001</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>maxIterations <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Set a seed for reproducibility</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialization: Randomly initialize the W matrix from the data</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>W <span class="ot">&lt;-</span> <span class="fu">t</span>(input_data[<span class="fu">sample</span>(N_data, <span class="at">size =</span> nPcs), , <span class="at">drop =</span> <span class="cn">FALSE</span>])</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>W <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="fu">length</span>(W)), <span class="fu">nrow</span>(W), <span class="fu">ncol</span>(W))</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Precompute W'W for efficiency</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>WtW <span class="ot">&lt;-</span> <span class="fu">crossprod</span>(W)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the latent representation Z based on the initial W</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>Z <span class="ot">&lt;-</span> input_data <span class="sc">%*%</span> W <span class="sc">%*%</span> <span class="fu">solve</span>(WtW)</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the initial reconstruction and its error</span></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>reconstructed <span class="ot">&lt;-</span> Z <span class="sc">%*%</span> <span class="fu">t</span>(W)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>error_ss <span class="ot">&lt;-</span> <span class="fu">sum</span>((reconstructed <span class="sc">-</span> input_data)<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> (N_data <span class="sc">*</span> D_data)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the iteration counter and the previous objective value for convergence checking</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>iteration <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>previous <span class="ot">&lt;-</span> <span class="cn">Inf</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Start the EM algorithm</span></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> (<span class="cn">TRUE</span>) {</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>  <span class="co"># E-Step: Estimate the covariance of the latent variable Z</span></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>  Z_cov <span class="ot">&lt;-</span> <span class="fu">solve</span>(<span class="fu">diag</span>(nPcs) <span class="sc">+</span> WtW<span class="sc">/</span>error_ss)</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the posterior mean of Z</span></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>  Z <span class="ot">&lt;-</span> input_data <span class="sc">%*%</span> W <span class="sc">%*%</span> Z_cov<span class="sc">/</span>error_ss</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>  ZtZ <span class="ot">&lt;-</span> <span class="fu">crossprod</span>(Z)</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>  <span class="co"># M-Step: Update W based on the estimated Z</span></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>  W <span class="ot">&lt;-</span> (<span class="fu">t</span>(input_data) <span class="sc">%*%</span> Z) <span class="sc">%*%</span> <span class="fu">solve</span>((ZtZ <span class="sc">+</span> N_data <span class="sc">*</span> Z_cov))</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>  WtW <span class="ot">&lt;-</span> <span class="fu">crossprod</span>(W)</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Recalculate the reconstruction error based on the updated W</span></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>  error_ss <span class="ot">&lt;-</span> (<span class="fu">sum</span>((W <span class="sc">%*%</span> <span class="fu">t</span>(Z) <span class="sc">-</span> <span class="fu">t</span>(input_data))<span class="sc">^</span><span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>                 N_data <span class="sc">*</span> <span class="fu">sum</span>(WtW <span class="sc">%*%</span> Z_cov))<span class="sc">/</span>(N_data <span class="sc">*</span> D_data)</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate the EM objective (the lower bound of the log-likelihood)</span></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>  obj_val <span class="ot">&lt;-</span> N_data <span class="sc">*</span> (D_data <span class="sc">*</span> <span class="fu">log</span>(error_ss) <span class="sc">+</span> </span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>                         <span class="fu">sum</span>(<span class="fu">diag</span>(Z_cov)) <span class="sc">-</span> <span class="fu">log</span>(<span class="fu">det</span>(Z_cov))) <span class="sc">+</span> <span class="fu">sum</span>(<span class="fu">diag</span>(ZtZ))</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Check for convergence</span></span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>  relative_change <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="dv">1</span> <span class="sc">-</span> obj_val<span class="sc">/</span>previous)</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>  previous <span class="ot">&lt;-</span> obj_val</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>  iteration <span class="ot">&lt;-</span> iteration <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (relative_change <span class="sc">&lt;</span> threshold <span class="sc">|</span> iteration <span class="sc">&gt;</span> maxIterations) {</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">break</span></span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>  } </span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a><span class="co"># Orthogonalize W for stability</span></span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>W <span class="ot">&lt;-</span> <span class="fu">svd</span>(W)<span class="sc">$</span>u</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a><span class="co"># Recalculate eigenvalues and eigenvectors after orthogonalization</span></span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>eig_vals <span class="ot">&lt;-</span> <span class="fu">eigen</span>(<span class="fu">cov</span>(input_data <span class="sc">%*%</span> W))<span class="sc">$</span>values</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>eig_vecs <span class="ot">&lt;-</span> <span class="fu">eigen</span>(<span class="fu">cov</span>(input_data <span class="sc">%*%</span> W))<span class="sc">$</span>vectors</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a><span class="co"># Update W based on the new eigenvectors</span></span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a>loadings <span class="ot">&lt;-</span> W <span class="sc">%*%</span> eig_vecs</span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a>scores <span class="ot">&lt;-</span> input_data <span class="sc">%*%</span> loadings</span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(scores,<span class="at">xlab=</span><span class="st">"pc1"</span>,<span class="at">ylab=</span><span class="st">"pc2"</span>,<span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="bayesian-principal-component-analysis-bpca" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-principal-component-analysis-bpca">Bayesian Principal Component Analysis (BPCA)</h2>
<p>In the traditional Probabilistic Principal Component Analysis (PPCA), we made certain probabilistic assumptions, specifically over the latent variables <span class="math inline">\(Z\)</span> and the noise term <span class="math inline">\(\epsilon\)</span>. The other parameters were treated as non-probabilistic. However, in BPCA, we take a step further by assuming a probabilistic distribution over all the parameters. This provides a more comprehensive probabilistic model.</p>
<p>Given the linear relationship: <span class="math display">\[ \mathbf{x}_n = \mathbf{W}\mathbf{z}_n + \boldsymbol{\epsilon}_n \]</span></p>
<p>In BPCA, we make the following probabilistic assumptions:</p>
<ol type="1">
<li><p>The latent variables <span class="math inline">\(\mathbf z\)</span> follow a standard normal distribution: <span class="math display">\[ \mathbf z \sim \mathcal{N}(0, 1) \]</span></p></li>
<li><p>The weight matrix <span class="math inline">\(\mathbf{W}\)</span> also follows a standard normal distribution: <span class="math display">\[ \mathbf{W} \sim \mathcal{N}(0, 1) \]</span> Both the latent variables and the weight matrix are assumed to follow standard normal distributions. This assumption is in line with the traditional PCA where the principal components are orthogonal and typically standardized to have unit variance. The normal distribution assumption implies that the values of the latent variables and weights are most likely to be around their means (which is zero) and decrease in likelihood as they move away from the mean.</p></li>
<li><p>The precision parameter <span class="math inline">\(\tau\)</span> follows a gamma distribution with parameters <span class="math inline">\(\alpha_0\)</span> and <span class="math inline">\(\beta_0\)</span>: <span class="math display">\[ \tau \sim \mathcal{G}(\alpha_0, \beta_0) \]</span> The gamma distribution is a flexible choice for modeling positive continuous variables like precision. The shape and rate parameters <span class="math inline">\(\alpha_0\)</span> and <span class="math inline">\(\beta_0\)</span> can be seen as hyperparameters, and their values can be chosen based on prior knowledge or set in a non-informative manner.</p></li>
<li><p>The noise term <span class="math inline">\(\epsilon_n\)</span> is normally distributed with mean 0 and precision <span class="math inline">\(\tau^{-1}\)</span>: <span class="math display">\[ \epsilon_n \sim \mathcal{N}(0, \tau^{-1}) \]</span> This is a common assumption in many statistical models, implying that the errors (or deviations from the model) are symmetrically distributed around zero. The variance of this noise is controlled by the precision parameter <span class="math inline">\(\tau\)</span>.</p></li>
<li><p>The observed data <span class="math inline">\(\mathbf{x}_n\)</span> follows a normal distribution with mean <span class="math inline">\(\mathbf W\mathbf z_n\)</span> and covariance <span class="math inline">\(\tau^{-1}\)</span>: <span class="math display">\[ \mathbf{x}_n \sim \mathcal{N}(\mathbf W\mathbf z_n, \tau^{-1} \mathbf ) \]</span> The choice of a normal distribution here signifies that the observed data points are most likely to lie close to the subspace spanned by the principal components and deviations from this subspace are captured by the noise term.</p></li>
</ol>
<p>One of the main advantages of BPCA over traditional PCA is that it provides a probabilistic framework, allowing us to quantify the uncertainties associated with the estimated parameters. In addition, BPCA can automatically determine the number of relevant principal components, unlike traditional PCA where the number of components needs to be specified or chosen.</p>
<p>In BPCA, our primary parameters of interest are the latent variables <span class="math inline">\(\mathbf{z}\)</span>, the weight matrix <span class="math inline">\(\mathbf{W}\)</span>, the precision parameter <span class="math inline">\(\tau\)</span>, and the noise term <span class="math inline">\(\epsilon_n\)</span>. Bayesian inference provides a good way to estimate these parameters, but exact inference can be computationally difficult, especially in high-dimensional setting This is where we can use algorithms like Variational Inference (VI) or MCMC (Markov Chain Monte Carlo) to simplify the problem. We are going to use Variational Inference here. This is an approximate inference technique that turns the inference problem into an optimization problem. The idea is to approximate the true posterior distribution of the parameters with a simpler, factorized distribution, referred to as the “mean-field” approximation.</p>
<p>We are going to assume that the approximate posterior factorizes across all the parameters, i.e., <span class="math display">\[q(\mathbf{z}, \mathbf{W}, \tau, \epsilon_n) = q(\mathbf{z})q(\mathbf{W})q(\tau)q(\epsilon_n)\]</span></p>
<p>The goal here is to minimize the KL divergence between the approximate posterior and the true posterior. This is equivalent to maximizing the Evidence Lower BOund (ELBO), which provides a lower bound to the log marginal likelihood of the data. Using an iterative algorithm, we adjust the parameters of our mean-field distribution to maximize the ELBO. Common techniques include coordinate ascent or gradient-based methods can be used. Once the ELBO is maximized, the parameters of the factorized distributions give us the approximate posterior means and variances for <span class="math inline">\(\mathbf{z}\)</span>, <span class="math inline">\(\mathbf{W}\)</span>, <span class="math inline">\(\tau\)</span>, and <span class="math inline">\(\epsilon_n\)</span>. We can then use the estimated parameters to generate new data points, reconstruct the original data with reduced dimensions, or project new observations onto the principal components, thereby facilitating visualization, clustering, etc.</p>
<p>R provides an excellent interface to Stan through the “rstan” package, allowing users to build, fit, and interrogate complex Bayesian models with ease. We are going to use rstan here. <strong>You can run the script if you have succesfully installed rstan otherwise you can skip running the scripts</strong></p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-7_bfd46fca9b16d4403699c8c2734a3a68">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(rstan)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure rstan options</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rstan_options</span>(<span class="at">auto_write =</span> <span class="cn">FALSE</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the number of cores for parallel processing</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">mc.cores =</span> parallel<span class="sc">::</span><span class="fu">detectCores</span>())</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the BPCA model in Stan language</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>bpca <span class="ot">&lt;-</span> <span class="st">"</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="st">        int&lt;lower=0&gt; N; // Number of samples</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="st">        int&lt;lower=0&gt; D; // The original dimension</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="st">        int&lt;lower=0&gt; K; // The latent dimension</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="st">        matrix[N, D] X; // The data matrix</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="st">    parameters {</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="st">        matrix[N, K] Z; // The latent matrix</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="st">        matrix[D, K] W; // The weight matrix</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="st">        real&lt;lower=0&gt; tau; // Noise term </span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="st">    transformed parameters{</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a><span class="st">        real&lt;lower=0&gt; t_tau; // Transformed precision term for noise</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a><span class="st">    t_tau = inv(sqrt(tau)); // Compute the inverse of the square root of tau</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="st">    model {</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a><span class="st">        // Prior distributions for the latent matrix and weight matrix</span></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a><span class="st">        to_vector(Z) ~ normal(0,1);</span></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a><span class="st">        to_vector(W)~ normal(0, 1);</span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a><span class="st">        </span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a><span class="st">        // Prior distribution for the noise precision term</span></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a><span class="st">        tau ~ gamma(1,1);               </span></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a><span class="st">        </span></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a><span class="st">        // Likelihood for the observed data</span></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a><span class="st">        to_vector(X) ~ normal(to_vector(Z*W'), t_tau);</span></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a><span class="st">    }"</span></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile the Stan model</span></span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>bpca_model <span class="ot">&lt;-</span> <span class="fu">stan_model</span>(<span class="at">model_code =</span> bpca)</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and preprocess the breast cancer dataset</span></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">scale</span>(breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>mrna,<span class="at">scale =</span> T,<span class="at">center =</span> T)</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the data for Stan</span></span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>data_input <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">N =</span> <span class="fu">dim</span>(X)[<span class="dv">1</span>], <span class="at">D =</span> <span class="fu">dim</span>(X)[<span class="dv">2</span>], <span class="at">K =</span> <span class="dv">2</span>, <span class="at">X =</span> X)</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seed for reproducibility</span></span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">200</span>)</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the BPCA model using Variational Bayes with the meanfield algorithm</span></span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>bpca_fit <span class="ot">&lt;-</span> <span class="fu">vb</span>(bpca_model, <span class="at">data =</span> data_input, <span class="at">algorithm =</span> <span class="st">"meanfield"</span>, <span class="at">iter =</span> <span class="dv">1000</span>, <span class="at">output_samples =</span> <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Chain 1: ------------------------------------------------------------
Chain 1: EXPERIMENTAL ALGORITHM:
Chain 1:   This procedure has not been thoroughly tested and may be unstable
Chain 1:   or buggy. The interface is subject to change.
Chain 1: ------------------------------------------------------------
Chain 1: 
Chain 1: 
Chain 1: 
Chain 1: Gradient evaluation took 0.001886 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 18.86 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Begin eta adaptation.
Chain 1: Iteration:   1 / 250 [  0%]  (Adaptation)
Chain 1: Iteration:  50 / 250 [ 20%]  (Adaptation)
Chain 1: Iteration: 100 / 250 [ 40%]  (Adaptation)
Chain 1: Iteration: 150 / 250 [ 60%]  (Adaptation)
Chain 1: Iteration: 200 / 250 [ 80%]  (Adaptation)
Chain 1: Success! Found best value [eta = 1] earlier than expected.
Chain 1: 
Chain 1: Begin stochastic gradient ascent.
Chain 1:   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes 
Chain 1:    100       -40058.050             1.000            1.000
Chain 1:    200       -38590.189             0.519            1.000
Chain 1:    300       -38538.645             0.020            0.038
Chain 1:    400       -38530.234             0.001            0.001   MEAN ELBO CONVERGED   MEDIAN ELBO CONVERGED
Chain 1: 
Chain 1: Drawing a sample of size 100 from the approximate posterior... 
Chain 1: COMPLETED.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the latent scores from the fit</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>scores <span class="ot">&lt;-</span> <span class="fu">apply</span>(<span class="fu">extract</span>(bpca_fit,<span class="st">"Z"</span>)[[<span class="dv">1</span>]], <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>), mean)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the latent scores with colors representing subtypes</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(scores,<span class="at">xlab=</span><span class="st">"pc1"</span>,<span class="at">ylab=</span><span class="st">"pc2"</span>,<span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The Stan code here is structured into four main sections, each serving a purpose in the Bayesian modeling framework. The <code>data</code> section declares the observed data and its dimensions, specifying the number of samples (N), the original data dimension (D), the latent dimension (K), and the actual data matrix (X). The <code>parameters</code> section introduces the model’s primary unknowns: the latent matrix (Z) that captures the underlying structure, the weight matrix (W) that maps latent variables to the observed space, and the noise precision parameter (tau). In the <code>transformed parameters</code> section, we computed a derived parameter, t_tau as the inverse of the square root of tau, offering a transformed precision term for the noise. Finally, the <code>model</code> section defines the probabilistic relationships in the model. Here, prior distributions are set for the latent matrix, weight matrix, and noise precision term, while the likelihood of the observed data is defined based on the latent scores, weight matrix, and the transformed noise precision.</p>
<p>The rest of the code essentially just compile the Stan code, prepare the data and run the inference. Probably one of the trickiest part of the code is <code>apply(extract(bpca_fit,"Z")[[1]], c(2,3), mean)</code>. <strong>Can you guess what does this do?</strong></p>
<p>If you remember, in the context of Bayesian analysis, we don’t deal with point estimate but we have a complete distribution over the parameters of interest. As the consequence we don’t have a single PCA score (PC) for each data point but rather we have a complete distribution. we chose to draw 100 samples (<code>output_samples</code>) from this distribution so we have for each data point 100 scores. I just took the average but we could take any of them or plot the complete distribution.</p>
<p>We have now implemented a complete Bayesian PCA in R and Stan. Time to move towards integration using two data views only.</p>
</section>
</section>
<section id="canonical-correlation-analysis-cca-two-datasets" class="level1">
<h1>Canonical Correlation Analysis CCA (two datasets)</h1>
<p>Canonical Correlation Analysis (CCA) is similar to PCA with the capability to analyze multivariate correlations between two datasets. While PCA focuses on maximizing variance within a single dataset, CCA identifies linear combinations of variables from two datasets that are maximally correlated. It provides pairs of canonical variables and their associated canonical correlations, giving insights into the shared structure and relationships between datasets. This is particularly suited in multi-omics studies, where understanding the interplay between different types of biological data is crucial.</p>
<section id="mathematical-foundations" class="level2">
<h2 class="anchored" data-anchor-id="mathematical-foundations">Mathematical Foundations</h2>
<p>CCA seeks to find pairs of linear combinations, one from each dataset, that are maximally correlated. If we have two datasets <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, the canonical correlations are obtained by solving the optimization problem:</p>
<p><span class="math display">\[
\max_{a, b} \rho = \text{corr}(a^T X, b^T Y)
\]</span></p>
<p>where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are the canonical weights, and <span class="math inline">\(\rho\)</span> is the canonical correlation.</p>
<p>The cross-covariance matrix between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> plays a central role in calculating CCA weights. We compute it and then apply SVD to find the weights and correlations. The process is similar to performing SVD in PCA but extends to exploring relationships between two datasets.</p>
<p><span class="math display">\[
\text{SVD}(\Sigma_{XY}) = U \Lambda V^T
\]</span></p>
<p>where <span class="math inline">\(\Sigma_{XY}\)</span> is the cross-covariance matrix, <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> are the canonical weights for <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, and <span class="math inline">\(\Lambda\)</span> contains the canonical correlations.</p>
<p>We can now find the canonical variables:</p>
<p><span class="math display">\[
T_x = XU
\]</span> <span class="math display">\[
T_y = YV
\]</span></p>
<p>After finding the first pair, we use a deflation process to remove their effect and proceed to find the next pair. This iterative process continues until we extract the desired number of canonical variable pairs.</p>
<p><span class="math display">\[
X = X-T_x(X^TT_U(T^T_UT_U)^{-1})^T
\]</span> and for <span class="math inline">\(Y\)</span></p>
<p><span class="math display">\[
Y = Y-T_y(Y^TT_U(T^T_UT_U)^{-1})^T
\]</span> The process is repeated to extract additional pairs of canonical variables.</p>
<p>Let’s have a look at how we can derive this in R using miRNA and mRNA data</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-8_d926a4a72ef94078264e99c618c63f07">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># center both of the datasets</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>X_centered <span class="ot">&lt;-</span> <span class="fu">scale</span>(breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>mrna, <span class="at">scale =</span> <span class="cn">FALSE</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>Y_centered <span class="ot">&lt;-</span> <span class="fu">scale</span>(breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>protein, <span class="at">scale =</span> <span class="cn">FALSE</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate cross-covariance matrix</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>cross_cov <span class="ot">&lt;-</span> <span class="fu">t</span>(X_centered)<span class="sc">%*%</span>Y_centered</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co"># do a svd (single eigenvector) this is going to give us a signle CCA component</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>svd_result <span class="ot">&lt;-</span> <span class="fu">svd</span>(cross_cov,<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co"># extract the vectors</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>U <span class="ot">&lt;-</span> svd_result<span class="sc">$</span>u</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>V <span class="ot">&lt;-</span> svd_result<span class="sc">$</span>v</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the first canonical vectors (the most correlated latent factors)</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>canonical_vars_X <span class="ot">&lt;-</span> X_centered <span class="sc">%*%</span> U</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>canonical_vars_Y <span class="ot">&lt;-</span> Y_centered <span class="sc">%*%</span> V</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co"># deflate the original matrices</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>X_centered <span class="ot">&lt;-</span> X_centered <span class="sc">-</span> canonical_vars_X <span class="sc">%*%</span> <span class="fu">t</span>((<span class="fu">t</span>(X_centered)<span class="sc">%*%</span>(canonical_vars_X)<span class="sc">%*%</span><span class="fu">solve</span>(<span class="fu">t</span>(canonical_vars_X)<span class="sc">%*%</span>(canonical_vars_X))))</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>Y_centered <span class="ot">&lt;-</span> Y_centered <span class="sc">-</span> canonical_vars_Y <span class="sc">%*%</span> </span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">t</span>(<span class="fu">t</span>(Y_centered)<span class="sc">%*%</span>(canonical_vars_Y)<span class="sc">%*%</span><span class="fu">solve</span>(<span class="fu">t</span>(canonical_vars_Y)<span class="sc">%*%</span>(canonical_vars_Y)))</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="co"># redo the svd for the second component</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>cross_cov <span class="ot">&lt;-</span> <span class="fu">t</span>(X_centered)<span class="sc">%*%</span>Y_centered</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>svd_result <span class="ot">&lt;-</span> <span class="fu">svd</span>(cross_cov,<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>U <span class="ot">&lt;-</span> svd_result<span class="sc">$</span>u</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>V <span class="ot">&lt;-</span> svd_result<span class="sc">$</span>v</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the second canonical vectors (the second most correlated latent factors)</span></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>canonical_vars_X2 <span class="ot">&lt;-</span> X_centered <span class="sc">%*%</span> U</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>canonical_vars_Y2 <span class="ot">&lt;-</span> Y_centered <span class="sc">%*%</span> V</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(canonical_vars_X,canonical_vars_X2,<span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype,<span class="at">xlab=</span><span class="st">"l1"</span>,<span class="at">ylab=</span><span class="st">"l2"</span>,<span class="at">main=</span><span class="st">"CCA protein"</span>)</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(canonical_vars_Y,canonical_vars_Y2,<span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype,<span class="at">xlab=</span><span class="st">"l1"</span>,<span class="at">ylab=</span><span class="st">"l2"</span>,<span class="at">main=</span><span class="st">"CCA protein"</span>)</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(canonical_vars_X,canonical_vars_Y,<span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype,<span class="at">xlab=</span><span class="st">"mRNA"</span>,<span class="at">ylab=</span><span class="st">"protein"</span>,<span class="at">main=</span><span class="st">"l1"</span>)</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(canonical_vars_X2,canonical_vars_Y2,<span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype,<span class="at">xlab=</span><span class="st">"mRNA"</span>,<span class="at">ylab=</span><span class="st">"protein"</span>,<span class="at">main=</span><span class="st">"l2"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The plot above clearly shows that we ended up having a shared pattern in <code>l1</code> (first CCA component). L1 captures the primary mode of correlation between protein and mRNA expression data. It represents the linear combinations of protein and mRNAs that are most strongly correlated. Since our interest right now is in the suptypes, we can probably ignore the second latent factor but we might as well try to explaining based on some other factors.</p>
<p>In the context of CCA, loadings play a role similar to that in PCA, yet they have a distinct interpretation. Similar to PCA, where loadings indicate the contribution of each original variable to the principal components, in CCA, the loadings show the contribution of each variable to the canonical variables. However, the difference lies in their meaning. While PCA loadings represent the contribution to the variance within a single dataset, CCA loadings show the contribution to the correlation between two datasets.</p>
</section>
<section id="bayesian-canonical-correlation-analysis-bcca" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-canonical-correlation-analysis-bcca">Bayesian Canonical Correlation Analysis (BCCA)</h2>
<p>The idea of Bayesian Canonical Correlation Analysis (BCCA) is simple. Recall that in BPCA we had <span class="math inline">\(X = ZW^T + \epsilon\)</span> in CCA however we have two data views (<span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>) that we are after a shared latent factor for them. So we can rewrite our BPCA equations:</p>
<p><span class="math display">\[X = ZW_x^T + \epsilon_x\]</span> <span class="math display">\[Y = ZW_y^T + \epsilon_y\]</span></p>
<p>If you look a the equation we can see we have a shared latent factor (<span class="math inline">\(Z\)</span>) but weights and noise are different across the dataset. So our latent factor <span class="math inline">\(Z\)</span> is going to capture the shared pattern using a global score and in addition the weights can be used to project the original data into data view specific scores.</p>
<p>In BCCA also: 1. The latent variables <span class="math inline">\(\mathbf z\)</span> follow a standard normal distribution: <span class="math display">\[ \mathbf z \sim \mathcal{N}(0, 1) \]</span> 2. The weight matrix for both datasets <span class="math inline">\(\mathbf{W_{x,y}}\)</span> also follows a standard normal distribution: <span class="math display">\[ \mathbf{W_{x,y}} \sim \mathcal{N}(0, 1) \]</span></p>
<ol start="3" type="1">
<li><p>The precision parameter <span class="math inline">\(\tau_{x,y}\)</span> follows a gamma distribution with parameters <span class="math inline">\(\alpha_0\)</span> and <span class="math inline">\(\beta_0\)</span>: <span class="math display">\[ \tau \sim \mathcal{G}(\alpha_0, \beta_0) \]</span></p></li>
<li><p>The noise term <span class="math inline">\(\epsilon_n\)</span> is also normally distributed for both dataset with mean 0 and precision <span class="math inline">\(\tau^{-1}\)</span>: <span class="math display">\[ \epsilon_n \sim \mathcal{N}(0, \tau^{-1}) \]</span></p></li>
<li><p>The observed data <span class="math inline">\(\mathbf{x}_n\)</span> and <span class="math inline">\(\mathbf{y}_n\)</span> follows a normal distribution with mean <span class="math inline">\(\mathbf W_x\mathbf z_n\)</span> and <span class="math inline">\(\mathbf W_y\mathbf z_n\)</span> and covariance <span class="math inline">\(\tau_{x,y}^{-1}\)</span> so <span class="math display">\[ \mathbf{x}_n \sim \mathcal{N}(\mathbf W_x\mathbf z_n, \tau_x^{-1} \mathbf ) \]</span> and <span class="math display">\[ \mathbf{y}_n \sim \mathcal{N}(\mathbf W_y\mathbf z_n, \tau_y^{-1} \mathbf ) \]</span>.</p></li>
</ol>
<p>The rest of the optimization etc are similar to those of BPCA. Let’s try to implement this:</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-9_55ef8de41d93259869865ddde1d197b0">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the rstan library for Bayesian analysis using Stan</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(rstan)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set rstan options for automatic caching and multi-core processing</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="fu">rstan_options</span>(<span class="at">auto_write =</span> <span class="cn">FALSE</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">mc.cores =</span> parallel<span class="sc">::</span><span class="fu">detectCores</span>())</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Fix the random seed for reproducibility</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the Canonical Correlation Analysis (CCA) model in Stan language</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>cca2 <span class="ot">&lt;-</span> <span class="st">"</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="st">        int&lt;lower=0&gt; N; // Number of samples</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="st">        int&lt;lower=0&gt; D1; // The original dimension</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="st">        int&lt;lower=0&gt; D2; // The original dimension</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="st">        int&lt;lower=0&gt; K; // The latent dimension</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a><span class="st">        matrix[N, D1] X1; // The data matrix</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="st">        matrix[N, D2] X2; // The data matrix</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="st">    parameters {</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="st">        matrix[N, K] Z; // The latent matrix</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a><span class="st">        matrix[D1, K] W1; // The weight matrix</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a><span class="st">        matrix[D2, K] W2; // The weight matrix</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="st">        real&lt;lower=0&gt; tau1; // Noise term </span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a><span class="st">        real&lt;lower=0&gt; tau2; // Noise term </span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a><span class="st">    transformed parameters{</span></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="st">        real&lt;lower=0&gt; t_tau1;</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a><span class="st">    t_tau1 = inv(sqrt(tau1));</span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a><span class="st">        real&lt;lower=0&gt; t_tau2;</span></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a><span class="st">    t_tau2 = inv(sqrt(tau2));</span></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a><span class="st">    model {</span></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a><span class="st">        tau1 ~ gamma(1,1);</span></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a><span class="st">        tau2 ~ gamma(1,1);</span></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a><span class="st">        to_vector(Z) ~ normal(0,1);</span></span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a><span class="st">        to_vector(W1)~ normal(0, 1);</span></span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a><span class="st">        to_vector(W2)~ normal(0, 1);</span></span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a><span class="st">        to_vector(X1) ~ normal(to_vector(Z*W1'), t_tau1);</span></span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a><span class="st">        to_vector(X2) ~ normal(to_vector(Z*W2'), t_tau2);</span></span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a><span class="st">    }"</span></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Compile the Stan model for CCA</span></span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>cca_model <span class="ot">&lt;-</span> <span class="fu">stan_model</span>(<span class="at">model_code =</span> cca2)</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and preprocess the breast cancer mRNA and protein datasets</span></span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>X1 <span class="ot">&lt;-</span> <span class="fu">scale</span>(breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>mrna,<span class="at">scale =</span> F,<span class="at">center =</span> T)</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">scale</span>(breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>protein,<span class="at">scale =</span> F,<span class="at">center =</span> T)</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the data for the Stan model</span></span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">N =</span> <span class="fu">dim</span>(X)[<span class="dv">1</span>], <span class="at">D1 =</span> <span class="fu">dim</span>(X)[<span class="dv">2</span>], <span class="at">K =</span> <span class="dv">2</span>, <span class="at">X1 =</span> X1, <span class="at">X2 =</span> Y, <span class="at">D2 =</span> <span class="fu">dim</span>(Y)[<span class="dv">2</span>])</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a><span class="co"># Set another random seed for reproducibility in the inference step</span></span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">200</span>)</span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the CCA model using Variational Bayes with the meanfield algorithm</span></span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a>cca_fit <span class="ot">&lt;-</span> <span class="fu">vb</span>(cca_model, <span class="at">data =</span> data, <span class="at">algorithm =</span> <span class="st">"meanfield"</span>, <span class="at">iter =</span> <span class="dv">1000</span>, <span class="at">output_samples =</span> <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Chain 1: ------------------------------------------------------------
Chain 1: EXPERIMENTAL ALGORITHM:
Chain 1:   This procedure has not been thoroughly tested and may be unstable
Chain 1:   or buggy. The interface is subject to change.
Chain 1: ------------------------------------------------------------
Chain 1: 
Chain 1: 
Chain 1: 
Chain 1: Gradient evaluation took 0.00208 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 20.8 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Begin eta adaptation.
Chain 1: Iteration:   1 / 250 [  0%]  (Adaptation)
Chain 1: Iteration:  50 / 250 [ 20%]  (Adaptation)
Chain 1: Iteration: 100 / 250 [ 40%]  (Adaptation)
Chain 1: Iteration: 150 / 250 [ 60%]  (Adaptation)
Chain 1: Iteration: 200 / 250 [ 80%]  (Adaptation)
Chain 1: Success! Found best value [eta = 1] earlier than expected.
Chain 1: 
Chain 1: Begin stochastic gradient ascent.
Chain 1:   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes 
Chain 1:    100       -60643.836             1.000            1.000
Chain 1:    200       -59084.380             0.513            1.000
Chain 1:    300       -58991.764             0.014            0.026
Chain 1:    400       -58978.129             0.001            0.002   MEAN ELBO CONVERGED   MEDIAN ELBO CONVERGED
Chain 1: 
Chain 1: Drawing a sample of size 100 from the approximate posterior... 
Chain 1: COMPLETED.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Pareto k diagnostic value is 4.98. Resampling is disabled. Decreasing
tol_rel_obj may help if variational algorithm has terminated prematurely.
Otherwise consider using sampling instead.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract and compute the average latent scores from the fit for global, mRNA, and protein data</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>scores_global <span class="ot">&lt;-</span> <span class="fu">apply</span>(<span class="fu">extract</span>(cca_fit,<span class="st">"Z"</span>)[[<span class="dv">1</span>]], <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>), mean)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>scores_x <span class="ot">&lt;-</span> X1<span class="sc">%*%</span> <span class="fu">apply</span>(<span class="fu">extract</span>(cca_fit,<span class="st">"W1"</span>)[[<span class="dv">1</span>]], <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>), mean)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>scores_y <span class="ot">&lt;-</span> Y<span class="sc">%*%</span> <span class="fu">apply</span>(<span class="fu">extract</span>(cca_fit,<span class="st">"W2"</span>)[[<span class="dv">1</span>]], <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>), mean)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the latent scores for mRNA, protein, and global datasets in a 2x2 grid layout</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(scores_x, <span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype, <span class="at">main=</span><span class="st">"BCCA mRNA"</span>, <span class="at">xlab=</span><span class="st">"L1"</span>, <span class="at">ylab=</span><span class="st">"L2"</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(scores_y, <span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype, <span class="at">main=</span><span class="st">"BCCA protein"</span>, <span class="at">xlab=</span><span class="st">"L1"</span>, <span class="at">ylab=</span><span class="st">"L2"</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(scores_global, <span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype, <span class="at">main=</span><span class="st">"BCCA global"</span>, <span class="at">xlab=</span><span class="st">"L1"</span>, <span class="at">ylab=</span><span class="st">"L2"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Based on the scores, can we say if we have captured shared pattern between our datasets? <strong>do A PCA on each of the datasets and comapre the results with what we got here</strong></p>
</section>
</section>
<section id="group-factor-analysis-gfa-multi-omics-factor-analysis-mofa" class="level1">
<h1>Group Factor Analysis (GFA) Multi-Omics Factor Analysis (MOFA)</h1>
<p>Group Factor Analysis (GFA) is simply the extension of CCA to more than two data views. Remember that in BCCA we had <span class="math inline">\(X = ZW_x^T + \epsilon_x\)</span> and <span class="math inline">\(Y = ZW_y^T + \epsilon_y\)</span> in which <span class="math inline">\(Z\)</span> was the common factor. In Group Factor Analysis (GFA), the idea is expanded to accommodate multiple data views, not just two as in CCA. In BCCA, we have the two data views represented by the equations <span class="math inline">\(X = ZW_x^T + \epsilon_x\)</span> and <span class="math inline">\(Y = ZW_y^T + \epsilon_y\)</span>, where <span class="math inline">\(Z\)</span> is the common latent factor, <span class="math inline">\(W_x\)</span> and <span class="math inline">\(W_y\)</span> are the loading matrices for <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> respectively, and <span class="math inline">\(\epsilon_x\)</span> and <span class="math inline">\(\epsilon_y\)</span> are the noise terms.</p>
<p>In GFA, for multiple data views <span class="math inline">\(V_1, V_2, ..., V_k\)</span>, the model can be written as:</p>
<p><span class="math display">\[ V_i = ZW_i^T + \epsilon_i \]</span></p>
<p>for <span class="math inline">\(i = 1, 2, ..., k\)</span>, where:</p>
<ul>
<li><span class="math inline">\(V_i\)</span> represents the <span class="math inline">\(i^{th}\)</span> data view.</li>
<li><span class="math inline">\(Z\)</span> is the shared common latent factor across all views.</li>
<li><span class="math inline">\(W_i\)</span> is the loading matrix for the <span class="math inline">\(i^{th}\)</span> data view.</li>
<li><span class="math inline">\(\epsilon_i\)</span> is the noise term for the <span class="math inline">\(i^{th}\)</span> data view.</li>
</ul>
<p>The objective of GFA is to find the common latent factor <span class="math inline">\(Z\)</span> and the individual loading matrices <span class="math inline">\(W_i\)</span> that best explain the variance in each of the data views while also capturing the shared information across all views.</p>
<p>The rest of the equations and optimization is identical to those of BCCA. So given the new definition let’s try to implement GFA in R using three data modalities (mRNA,protein and miRNA):</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-10_6d9e40ba468c8ac5beb34c87352a81db">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fix the random seed for reproducibility</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define GFA</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>gfa <span class="ot">&lt;-</span> <span class="st">"</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=1&gt; N;             // Number of data points</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=1&gt; K;             // Dimensionality of latent space</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=1&gt; M;             // Number of modalities</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=1&gt; SumP;          // Total number of features across all modalities</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=1&gt; P[M];          // Number of features for each modality</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="st">    matrix[N, SumP] x;          // Concatenated data</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="st">    matrix[K, SumP] W;          // Factor loading matrix</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="st">    vector&lt;lower=0&gt;[M] tau;       // Precision for each modality</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="st">    matrix[N, K] z;             // Latent variables</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="st">    matrix&lt;lower=0&gt;[M,K] alpha; // View-specific ARD prior</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a><span class="st">    transformed parameters{</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a><span class="st">        vector&lt;lower=0&gt;[M] t_tau;</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a><span class="st">    t_tau = inv(sqrt(tau));</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a><span class="st">    // fix z first</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a><span class="st">    to_vector(z) ~ normal(0,1);</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a><span class="st">    tau ~ gamma(1, 1);</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a><span class="st">    // Priors</span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a><span class="st">    int start;</span></span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a><span class="st">    start = 0;</span></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a><span class="st">        for (m in 1:M) {</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a><span class="st">            for (d in 1:P[m]) {</span></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a><span class="st">                start = start + 1;   </span></span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a><span class="st">                W[,start] ~ normal(0,1);</span></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a><span class="st">                x[,start] ~ normal(z*W[,start], t_tau[m]);  </span></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a><span class="st">                </span></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a><span class="st">            }</span></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a><span class="st">        }</span></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>gfa_model <span class="ot">&lt;-</span> <span class="fu">stan_model</span>(<span class="at">model_code =</span> gfa)</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and preprocess the breast cancer mRNA, mirna and protein datasets</span></span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>X1 <span class="ot">&lt;-</span> <span class="fu">scale</span>(breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>mrna,<span class="at">scale =</span> F,<span class="at">center =</span> T)</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a>X2 <span class="ot">&lt;-</span> <span class="fu">scale</span>(breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>protein,<span class="at">scale =</span> F,<span class="at">center =</span> T)</span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a>X3 <span class="ot">&lt;-</span> <span class="fu">scale</span>(breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>mirna,<span class="at">scale =</span> F,<span class="at">center =</span> T)</span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a><span class="co"># prepare the list</span></span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a>matrices_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a>  X1,</span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a>  X2,</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a>  X3</span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a>combined_data <span class="ot">&lt;-</span> <span class="fu">do.call</span>(cbind,matrices_list)</span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the data for the Stan model</span></span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a>stan_data <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fu">sapply</span>(matrices_list, nrow)[<span class="dv">1</span>],</span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a>  <span class="at">K =</span> <span class="dv">2</span>,</span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a>  <span class="at">P =</span> <span class="fu">sapply</span>(matrices_list, ncol),</span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a>  <span class="at">M =</span> <span class="fu">length</span>(matrices_list),</span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> combined_data,</span>
<span id="cb16-73"><a href="#cb16-73" aria-hidden="true" tabindex="-1"></a>  <span class="at">SumP =</span> <span class="fu">ncol</span>(combined_data)</span>
<span id="cb16-74"><a href="#cb16-74" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-75"><a href="#cb16-75" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb16-76"><a href="#cb16-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-77"><a href="#cb16-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Set another random seed for reproducibility in the inference step</span></span>
<span id="cb16-78"><a href="#cb16-78" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2000</span>)</span>
<span id="cb16-79"><a href="#cb16-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-80"><a href="#cb16-80" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the GFA model using Variational Bayes with the meanfield algorithm</span></span>
<span id="cb16-81"><a href="#cb16-81" aria-hidden="true" tabindex="-1"></a>gfa_fit <span class="ot">&lt;-</span> <span class="fu">vb</span>(gfa_model, <span class="at">data =</span> stan_data, <span class="at">algorithm =</span> <span class="st">"meanfield"</span>, <span class="at">iter =</span> <span class="dv">1000</span>, <span class="at">output_samples =</span> <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Chain 1: ------------------------------------------------------------
Chain 1: EXPERIMENTAL ALGORITHM:
Chain 1:   This procedure has not been thoroughly tested and may be unstable
Chain 1:   or buggy. The interface is subject to change.
Chain 1: ------------------------------------------------------------
Chain 1: 
Chain 1: 
Chain 1: 
Chain 1: Gradient evaluation took 0.006892 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 68.92 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Begin eta adaptation.
Chain 1: Iteration:   1 / 250 [  0%]  (Adaptation)
Chain 1: Iteration:  50 / 250 [ 20%]  (Adaptation)
Chain 1: Iteration: 100 / 250 [ 40%]  (Adaptation)
Chain 1: Iteration: 150 / 250 [ 60%]  (Adaptation)
Chain 1: Iteration: 200 / 250 [ 80%]  (Adaptation)
Chain 1: Success! Found best value [eta = 1] earlier than expected.
Chain 1: 
Chain 1: Begin stochastic gradient ascent.
Chain 1:   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes 
Chain 1:    100       -99211.110             1.000            1.000
Chain 1:    200       -97573.911             0.508            1.000
Chain 1:    300       -97485.188             0.009            0.017   MEAN ELBO CONVERGED
Chain 1: 
Chain 1: Drawing a sample of size 100 from the approximate posterior... 
Chain 1: COMPLETED.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Pareto k diagnostic value is 26.79. Resampling is disabled. Decreasing
tol_rel_obj may help if variational algorithm has terminated prematurely.
Otherwise consider using sampling instead.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract and compute the average latent scores from the fit for global, mRNA, and protein data</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>scores_global <span class="ot">&lt;-</span> <span class="fu">apply</span>(<span class="fu">extract</span>(gfa_fit,<span class="st">"z"</span>)[[<span class="dv">1</span>]], <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>), mean)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>W_mean <span class="ot">&lt;-</span><span class="fu">apply</span>(<span class="fu">extract</span>(gfa_fit,<span class="st">"W"</span>)[[<span class="dv">1</span>]], <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>), mean)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>W_mean_no_sparse<span class="ot">&lt;-</span>W_mean</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Separate W_mean based on modalities</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>W_list <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>start_col <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(m <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>stan_data<span class="sc">$</span>M) {</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    end_col <span class="ot">&lt;-</span> start_col <span class="sc">+</span> stan_data<span class="sc">$</span>P[m] <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    W_list[[m]] <span class="ot">&lt;-</span> W_mean[, start_col<span class="sc">:</span>end_col]</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    start_col <span class="ot">&lt;-</span> end_col <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>scores <span class="ot">&lt;-</span> <span class="fu">mapply</span>(<span class="cf">function</span>(x,y){<span class="fu">list</span>(x<span class="sc">%*%</span><span class="fu">t</span>(y))},<span class="at">x=</span>matrices_list,<span class="at">y=</span>W_list)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the latent scores for mRNA, protein, and global datasets in a 2x2 grid layout</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(scores[[<span class="dv">1</span>]], <span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype, <span class="at">main=</span><span class="st">"GFA mRNA"</span>, <span class="at">xlab=</span><span class="st">"L1"</span>, <span class="at">ylab=</span><span class="st">"L2"</span>)</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(scores[[<span class="dv">2</span>]], <span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype, <span class="at">main=</span><span class="st">"GFA protein"</span>, <span class="at">xlab=</span><span class="st">"L1"</span>, <span class="at">ylab=</span><span class="st">"L2"</span>)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(scores[[<span class="dv">3</span>]], <span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype, <span class="at">main=</span><span class="st">"GFA miRNA"</span>, <span class="at">xlab=</span><span class="st">"L1"</span>, <span class="at">ylab=</span><span class="st">"L2"</span>)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(scores_global, <span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype, <span class="at">main=</span><span class="st">"GFA global"</span>, <span class="at">xlab=</span><span class="st">"L1"</span>, <span class="at">ylab=</span><span class="st">"L2"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>In the code above, since Stan does not support ragged data structures (data structures with different lengths), we had to concatenate the data first, but then instruct Rstan to put different assumptions on different columns of the data depending on which modality it originates from.</p>
<p>The results are more or less clear; we have captured the shared pattern across these three datasets.</p>
<p>One more thing before talking about MOFA is that we have been omitting sparsity considerations in our model. Sparsity plays a crucial role in high-dimensional data analysis, ensuring that the model remains interpretable and avoids overfitting. Two popular approaches to incorporate sparsity are Automatic Relevance Determination (ARD) and the Spike-and-slab prior.</p>
<p>ARD is a form of Bayesian regularization where each feature is assigned its own regularization coefficient, allowing the model to effectively “turn off” irrelevant features by pushing their coefficients towards zero. This results in a more interpretable model where only the most relevant features contribute to the outcome. Mathematically, this can be represented as: <span class="math display">\[p(\mathbf{W}|\boldsymbol{\alpha}) = \prod_{k=1}^{K} N(\mathbf{w}_{:,k};0,\frac{1}{\alpha_{k}}I_{D})\]</span> <span class="math display">\[p(\boldsymbol{\alpha}) = \prod_{k=1}^{K} \mathcal{G}(\alpha_k; a_0^\alpha, b_0^\alpha)\]</span> where <span class="math inline">\(W\)</span> is the weight matrix and <span class="math inline">\(\alpha\)</span> represents the precision of the weights. The Gamma distribution shapes the hyperparameters <span class="math inline">\(\boldsymbol{\alpha}\)</span>, capturing the uncertainty associated with the inverse variance of the weights.</p>
<p>On the other hand, the Spike-and-slab prior combines two distributions: a spike at zero, representing the probability that a coefficient is exactly zero, and a slab, a continuous distribution reflecting the possible non-zero values of the coefficient. This mixture allows for both exact zeros and non-zero coefficients, making it a powerful tool for variable selection in high-dimensional settings. The prior can be represented as: <span class="math display">\[p(w_{d,k} | \alpha_k,\theta_k) = (1-\theta_k) \delta_0(w_{d,k}) + \theta_k N(w_{d,k};0, \alpha_k^{-1})\]</span> <span class="math display">\[p(\theta_k) = \mathcal{B}(\theta_k; a_0^\theta,b_0^\theta)\]</span> <span class="math display">\[p(\alpha_k) = \mathcal{G}(\alpha_k; a_0^\alpha, b_0^\alpha)\]</span></p>
<p>Here, the Beta distribution is utilized for modeling the hyperparameter <span class="math inline">\(\theta_k\)</span>, indicating the probability that a weight is non-zero. As the Beta distribution is defined between [0, 1], it’s a good fit for modeling probabilities.</p>
<p>Let’s try to incorporate these in the model.</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-11_3a7c7c8a00e9a09ffcbbfa3b411b24c4">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fix the random seed for reproducibility</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">100</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>gfa_sparse <span class="ot">&lt;-</span> <span class="st">"</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=1&gt; N;             // Number of data points</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=1&gt; K;             // Dimensionality of latent space</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=1&gt; M;             // Number of modalities</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=1&gt; SumP;          // Total number of features across all modalities</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="st">    int&lt;lower=1&gt; P[M];          // Number of features for each modality</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="st">    matrix[N, SumP] x;          // Concatenated data</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="st">    real a0_theta;              // Hyperparameter for Beta prior</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="st">    real b0_theta;              // Hyperparameter for Beta prior</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="st">    matrix[K, SumP] W;          // Factor loading matrix</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a><span class="st">    vector&lt;lower=0&gt;[M] tau;       // Precision for each modality</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a><span class="st">    matrix[N, K] z;             // Latent variables</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="st">    matrix&lt;lower=0&gt;[M,K] alpha; // View-specific ARD prior</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a><span class="st">    matrix&lt;lower=0, upper=1&gt;[K, SumP] theta; // Spike-and-slab mixing proportion</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a><span class="st">    transformed parameters{</span></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a><span class="st">        vector&lt;lower=0&gt;[M] t_tau;</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a><span class="st">    t_tau = inv(sqrt(tau));</span></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a><span class="st">    matrix&lt;lower=0&gt;[M,K] t_alpha; </span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a><span class="st">    t_alpha = inv(sqrt(alpha));</span></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a><span class="st">    // fix z first</span></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a><span class="st">    to_vector(z) ~ normal(0,1);</span></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a><span class="st">    tau ~ gamma(1, 1);</span></span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a><span class="st">    to_vector(alpha) ~ gamma(1e-2,1e-2);</span></span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a><span class="st">    // add aph</span></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a><span class="st">    // Priors</span></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a><span class="st">// Incorporating the ARD and spike-and-slab priors</span></span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a><span class="st">    int start;</span></span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a><span class="st">    start = 0;</span></span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a><span class="st">    for (m in 1:M) {</span></span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a><span class="st">        for (d in 1:P[m]) {</span></span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a><span class="st">            start = start + 1;   </span></span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a><span class="st">            </span></span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a><span class="st">            // Spike-and-slab prior</span></span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a><span class="st">            for (k in 1:K) {</span></span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a><span class="st">                </span></span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a><span class="st">                theta[k,start] ~ beta(a0_theta, b0_theta);</span></span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a><span class="st">                target += log_mix(theta[k, start],</span></span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a><span class="st">                                  normal_lpdf(W[k,start] | 0, t_alpha[m,k]),normal_lpdf(W[k,start] | 0, 1e-14));</span></span>
<span id="cb20-55"><a href="#cb20-55" aria-hidden="true" tabindex="-1"></a><span class="st">            }</span></span>
<span id="cb20-56"><a href="#cb20-56" aria-hidden="true" tabindex="-1"></a><span class="st">            </span></span>
<span id="cb20-57"><a href="#cb20-57" aria-hidden="true" tabindex="-1"></a><span class="st">            // Data likelihood</span></span>
<span id="cb20-58"><a href="#cb20-58" aria-hidden="true" tabindex="-1"></a><span class="st">            x[,start] ~ normal(z*W[,start], t_tau[m]);  </span></span>
<span id="cb20-59"><a href="#cb20-59" aria-hidden="true" tabindex="-1"></a><span class="st">        }</span></span>
<span id="cb20-60"><a href="#cb20-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-61"><a href="#cb20-61" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb20-62"><a href="#cb20-62" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb20-63"><a href="#cb20-63" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb20-64"><a href="#cb20-64" aria-hidden="true" tabindex="-1"></a><span class="st">"</span></span>
<span id="cb20-65"><a href="#cb20-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-66"><a href="#cb20-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-67"><a href="#cb20-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-68"><a href="#cb20-68" aria-hidden="true" tabindex="-1"></a>gfa_model <span class="ot">&lt;-</span> <span class="fu">stan_model</span>(<span class="at">model_code =</span> gfa_sparse)</span>
<span id="cb20-69"><a href="#cb20-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-70"><a href="#cb20-70" aria-hidden="true" tabindex="-1"></a><span class="co"># Load and preprocess the breast cancer mRNA and protein datasets</span></span>
<span id="cb20-71"><a href="#cb20-71" aria-hidden="true" tabindex="-1"></a>X1 <span class="ot">&lt;-</span> <span class="fu">scale</span>(breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>mrna,<span class="at">scale =</span> F,<span class="at">center =</span> T)</span>
<span id="cb20-72"><a href="#cb20-72" aria-hidden="true" tabindex="-1"></a>X2 <span class="ot">&lt;-</span> <span class="fu">scale</span>(breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>protein,<span class="at">scale =</span> F,<span class="at">center =</span> T)</span>
<span id="cb20-73"><a href="#cb20-73" aria-hidden="true" tabindex="-1"></a>X3 <span class="ot">&lt;-</span> <span class="fu">scale</span>(breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>mirna,<span class="at">scale =</span> F,<span class="at">center =</span> T)</span>
<span id="cb20-74"><a href="#cb20-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-75"><a href="#cb20-75" aria-hidden="true" tabindex="-1"></a><span class="co"># prepare the list</span></span>
<span id="cb20-76"><a href="#cb20-76" aria-hidden="true" tabindex="-1"></a>matrices_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb20-77"><a href="#cb20-77" aria-hidden="true" tabindex="-1"></a>  X1,</span>
<span id="cb20-78"><a href="#cb20-78" aria-hidden="true" tabindex="-1"></a>  X2,</span>
<span id="cb20-79"><a href="#cb20-79" aria-hidden="true" tabindex="-1"></a>  X3</span>
<span id="cb20-80"><a href="#cb20-80" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-81"><a href="#cb20-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-82"><a href="#cb20-82" aria-hidden="true" tabindex="-1"></a>combined_data <span class="ot">&lt;-</span> <span class="fu">do.call</span>(cbind,matrices_list)</span>
<span id="cb20-83"><a href="#cb20-83" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the data for the Stan model</span></span>
<span id="cb20-84"><a href="#cb20-84" aria-hidden="true" tabindex="-1"></a>stan_data <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb20-85"><a href="#cb20-85" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fu">sapply</span>(matrices_list, nrow)[<span class="dv">1</span>],</span>
<span id="cb20-86"><a href="#cb20-86" aria-hidden="true" tabindex="-1"></a>  <span class="at">K =</span> <span class="dv">2</span>,</span>
<span id="cb20-87"><a href="#cb20-87" aria-hidden="true" tabindex="-1"></a>  <span class="at">P =</span> <span class="fu">sapply</span>(matrices_list, ncol),</span>
<span id="cb20-88"><a href="#cb20-88" aria-hidden="true" tabindex="-1"></a>  <span class="at">M =</span> <span class="fu">length</span>(matrices_list),</span>
<span id="cb20-89"><a href="#cb20-89" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> combined_data,</span>
<span id="cb20-90"><a href="#cb20-90" aria-hidden="true" tabindex="-1"></a>  <span class="at">SumP =</span> <span class="fu">ncol</span>(combined_data),</span>
<span id="cb20-91"><a href="#cb20-91" aria-hidden="true" tabindex="-1"></a>  <span class="at">a0_theta=</span><span class="dv">1</span>,</span>
<span id="cb20-92"><a href="#cb20-92" aria-hidden="true" tabindex="-1"></a>  <span class="at">b0_theta=</span><span class="dv">1</span></span>
<span id="cb20-93"><a href="#cb20-93" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-94"><a href="#cb20-94" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-95"><a href="#cb20-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-96"><a href="#cb20-96" aria-hidden="true" tabindex="-1"></a><span class="co"># Set another random seed for reproducibility in the inference step</span></span>
<span id="cb20-97"><a href="#cb20-97" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">200</span>)</span>
<span id="cb20-98"><a href="#cb20-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-99"><a href="#cb20-99" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the GFA model using Variational Bayes with the meanfield algorithm</span></span>
<span id="cb20-100"><a href="#cb20-100" aria-hidden="true" tabindex="-1"></a>gfa_fit <span class="ot">&lt;-</span> <span class="fu">vb</span>(gfa_model, <span class="at">data =</span> stan_data, <span class="at">algorithm =</span> <span class="st">"meanfield"</span>, <span class="at">iter =</span> <span class="dv">1000</span>, <span class="at">output_samples =</span> <span class="dv">100</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Chain 1: ------------------------------------------------------------
Chain 1: EXPERIMENTAL ALGORITHM:
Chain 1:   This procedure has not been thoroughly tested and may be unstable
Chain 1:   or buggy. The interface is subject to change.
Chain 1: ------------------------------------------------------------
Chain 1: 
Chain 1: 
Chain 1: 
Chain 1: Gradient evaluation took 0.007134 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 71.34 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 
Chain 1: Begin eta adaptation.
Chain 1: Iteration:   1 / 250 [  0%]  (Adaptation)
Chain 1: Iteration:  50 / 250 [ 20%]  (Adaptation)
Chain 1: Iteration: 100 / 250 [ 40%]  (Adaptation)
Chain 1: Iteration: 150 / 250 [ 60%]  (Adaptation)
Chain 1: Iteration: 200 / 250 [ 80%]  (Adaptation)
Chain 1: Success! Found best value [eta = 1] earlier than expected.
Chain 1: 
Chain 1: Begin stochastic gradient ascent.
Chain 1:   iter             ELBO   delta_ELBO_mean   delta_ELBO_med   notes 
Chain 1:    100      -104607.753             1.000            1.000
Chain 1:    200       -98371.919             0.532            1.000
Chain 1:    300       -98212.222             0.033            0.063
Chain 1:    400       -98172.998             0.001            0.002   MEAN ELBO CONVERGED   MEDIAN ELBO CONVERGED
Chain 1: 
Chain 1: Drawing a sample of size 100 from the approximate posterior... 
Chain 1: COMPLETED.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Pareto k diagnostic value is 6.26. Resampling is disabled. Decreasing
tol_rel_obj may help if variational algorithm has terminated prematurely.
Otherwise consider using sampling instead.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract and compute the average latent scores from the fit for global, mRNA, protein, and miRNA data</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>scores_global <span class="ot">&lt;-</span> <span class="fu">apply</span>(<span class="fu">extract</span>(gfa_fit,<span class="st">"z"</span>)[[<span class="dv">1</span>]], <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>), mean)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>W_mean <span class="ot">&lt;-</span><span class="fu">apply</span>(<span class="fu">extract</span>(gfa_fit,<span class="st">"W"</span>)[[<span class="dv">1</span>]], <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>), mean)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Separate W_mean based on modalities</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>W_list <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>start_col <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(m <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>stan_data<span class="sc">$</span>M) {</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>  end_col <span class="ot">&lt;-</span> start_col <span class="sc">+</span> stan_data<span class="sc">$</span>P[m] <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>  W_list[[m]] <span class="ot">&lt;-</span> W_mean[, start_col<span class="sc">:</span>end_col]</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>  start_col <span class="ot">&lt;-</span> end_col <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate block scores</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>scores <span class="ot">&lt;-</span> <span class="fu">mapply</span>(<span class="cf">function</span>(x,y){<span class="fu">list</span>(x<span class="sc">%*%</span><span class="fu">t</span>(y))},<span class="at">x=</span>matrices_list,<span class="at">y=</span>W_list)</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the latent scores for mRNA, protein, and global datasets in a 2x2 grid layout</span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(scores[[<span class="dv">1</span>]], <span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype, <span class="at">main=</span><span class="st">"GFA mRNA"</span>, <span class="at">xlab=</span><span class="st">"L1"</span>, <span class="at">ylab=</span><span class="st">"L2"</span>)</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(scores[[<span class="dv">2</span>]], <span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype, <span class="at">main=</span><span class="st">"GFA protein"</span>, <span class="at">xlab=</span><span class="st">"L1"</span>, <span class="at">ylab=</span><span class="st">"L2"</span>)</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(scores[[<span class="dv">3</span>]], <span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype, <span class="at">main=</span><span class="st">"GFA miRNA"</span>, <span class="at">xlab=</span><span class="st">"L1"</span>, <span class="at">ylab=</span><span class="st">"L2"</span>)</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(scores_global, <span class="at">col=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype, <span class="at">main=</span><span class="st">"GFA global"</span>, <span class="at">xlab=</span><span class="st">"L1"</span>, <span class="at">ylab=</span><span class="st">"L2"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The above code computes the log of a mixture of two distributions. In the context of the spike-and-slab prior, this function is used to represent the spike (a point mass at zero) and the slab (a continuous distribution) for the weights. As said, the idea is to combine a “spike” (a point mass at zero, promoting sparsity) with a “slab” (a continuous distribution allowing for non-zero parameter values). By mixing these two distributions, the prior encourages the parameters to be close to zero (due to the spike) while allowing some to take non-zero values (due to the slab).</p>
<p>In practice however our parametrization might cause problems in inference.</p>
<p>MOFA uses re-parametrization of the weights <span class="math inline">\(w\)</span> as a product of a Gaussian random variable <span class="math inline">\(\hat{w}\)</span> and a Bernoulli random variable <span class="math inline">\(s, 12\)</span>, 4] resulting in the following prior:</p>
<p><span class="math display">\[
p\left(\hat{w}_{d, k}^{m}, s_{d, k}^{m}\right)=\mathcal{N}\left(\hat{w}_{d, k}^{m} \mid 0,1 / \alpha_{k}^{m}\right) \operatorname{Ber}\left(s_{d, k}^{m} \mid \theta_{k}^{m}\right)
\]</span> with hyper-parameters <span class="math inline">\(a_{0}^{\theta}, b_{0}^{\theta}=1\)</span> and <span class="math inline">\(a_{0}^{\alpha}, b_{0}^{\alpha}=1 e^{-14}\)</span> to get uninformative priors. A value of <span class="math inline">\(\theta_{k}^{m}\)</span> close to 0 implies that most of the weights of factor <span class="math inline">\(k\)</span> in view <span class="math inline">\(m\)</span> are shrinked to 0 , which is the definition of a sparse factor. In contrast, a value of <span class="math inline">\(\theta_{k}^{m}\)</span> close to 1 implies that most of the weights are non-zero, which is the definition of a non-sparse factor.</p>
<p>We cannot directly construct a spike-and-slab prior in Stan since it requires a discrete parameter. We are going to leave it as it is now! So all together with the code above, we have more or less reach the final joint probability of MOFA:</p>
<p><span class="math display">\[
\begin{aligned}
p(\mathbf{Y}, \hat{\mathbf{W}}, \mathbf{S}, \mathbf{Z}, \boldsymbol{\Theta}, \boldsymbol{\alpha}, \boldsymbol{\tau})= &amp; \prod_{m=1}^{M} \prod_{n=1}^{N} \prod_{d=1}^{D_{m}} \mathcal{N}\left(y_{n d}^{m} \mid \sum_{k=1}^{K} s_{d k}^{m} \hat{w}_{d k}^{m} z_{n k}, 1 / \tau_{d}\right) \\
&amp; \prod_{m=1}^{M} \prod_{d=1}^{D_{m}} \prod_{k=1}^{K} \mathcal{N}\left(\hat{w}_{d k}^{m} \mid 0,1 / \alpha_{k}^{m}\right) \operatorname{Ber}\left(s_{d, k}^{m} \mid \theta_{k}^{m}\right) \\
&amp; \prod_{n=1}^{N} \prod_{k=1}^{K} \mathcal{N}\left(z_{n k} \mid 0,1\right) \\
&amp; \prod_{m=1}^{M} \prod_{k=1}^{K} \operatorname{Beta}\left(\theta_{k}^{m} \mid a_{0}^{\theta}, b_{0}^{\theta}\right) \\
&amp; \prod_{m=1}^{M} \prod_{k=1}^{K} \mathcal{G}\left(\alpha_{k}^{m} \mid a_{0}^{\alpha}, b_{0}^{\alpha}\right) \\
&amp; \prod_{m=1}^{M} \prod_{d=1}^{D_{m}} \mathcal{G}\left(\tau_{d}^{m} \mid a_{0}^{\tau}, b_{0}^{\tau}\right) .
\end{aligned}
\]</span></p>
<p>MOFA follows GFA under the hood but it also allows one to use different priors depending on data distribution and also different levels of sparsity but the general idea is what we got to now. After going through the theory it is time to use MOFA to do data integration.</p>
</section>
<section id="data-integration-using-mofa2" class="level1">
<h1>Data integration using MOFA2</h1>
<p>In order to do data integration using MOFA we first have to construct a list of data matrices:</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-12_3b197d175b4f71caa94bfcf1d65a62af">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MOFA2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'MOFA2'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:stats':

    predict</code></pre>
</div>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># remove the subtype information</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>data_mofa <span class="ot">&lt;-</span> breast.TCGA<span class="sc">$</span>data.train[<span class="sc">-</span><span class="dv">4</span>]</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co"># we do transpose because mofa wants features in rows</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>data_mofa <span class="ot">&lt;-</span> <span class="fu">lapply</span>(data_mofa,t)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can then use <code>create_mofa</code> to create a MOFA object:</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-13_5d6079bc78dfec85906b651be78357e1">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>MOFAobject <span class="ot">&lt;-</span> <span class="fu">create_mofa</span>(data_mofa)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Creating MOFA object from a list of matrices (features as rows, sample as columns)...</code></pre>
</div>
</div>
<p>We can have a look at the structure of the input data:</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-14_8c36e96169cfb385b333caa7df167914">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_data_overview</span>(MOFAobject)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This essentially shows us how many samples we have and how many features per data view is there. If there is missing values it will be shown as white lines. But we don’t have missing values.</p>
<p>Before start modeling we should have a look at the distribution of the data to decide which distrubtion to use.</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-15_5a4cfaff082cf51380f155793be65e3f">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(data_mofa<span class="sc">$</span>mrna)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(data_mofa<span class="sc">$</span>protein)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(data_mofa<span class="sc">$</span>mirna)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>All of our data is normally distributed so we go for normal distribution. In practice MOFA allows us to select ‘gaussian’ for continuous data (e.g proteomics), ‘bernoulli’ for binary data (e.g.&nbsp;methylation) and ‘poisson’ for count data (e.g.&nbsp;RNA-Seq).</p>
<p>We can now set the parameters and train the model:</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-16_12ec04cf17b7fdc8907f70f9882f0576">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>model_opts <span class="ot">&lt;-</span> <span class="fu">get_default_model_options</span>(MOFAobject)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(model_opts)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>$likelihoods
     mirna       mrna    protein 
"gaussian" "gaussian" "gaussian" 

$num_factors
[1] 15

$spikeslab_factors
[1] FALSE

$spikeslab_weights
[1] FALSE

$ard_factors
[1] FALSE

$ard_weights
[1] TRUE</code></pre>
</div>
</div>
<p>We see that MOFA has select default (gaussian) likelyhood for all our data and include 15 factors (latent variables). It does not do Spike and Slap but ARD is switched on.</p>
<p>Let’s set the number of factors to 10 and continue</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-17_9928f7582256225bf86ea9f54888d798">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>model_opts<span class="sc">$</span>num_factors <span class="ot">&lt;-</span> <span class="dv">10</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can now start the training:</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-18_a8f2fb36d68f5e335b47c9d2ea5659dc">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>MOFAobject <span class="ot">&lt;-</span> <span class="fu">prepare_mofa</span>(MOFAobject,</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">model_options =</span> model_opts</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Checking data options...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>No data options specified, using default...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>No training options specified, using default...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Checking model options...</code></pre>
</div>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>MOFAobject <span class="ot">&lt;-</span> <span class="fu">invisible</span>(<span class="fu">run_mofa</span>(MOFAobject))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in run_mofa(MOFAobject): No output filename provided. Using /var/folders/kh/tgq9mmld6_v9z_h220trj0c40000gn/T//RtmptEmLD6/mofa_20231018-185049.hdf5 to store the trained model.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Connecting to the mofapy2 python package using reticulate (use_basilisk = FALSE)... 
    Please make sure to manually specify the right python binary when loading R with reticulate::use_python(..., force=TRUE) or the right conda environment with reticulate::use_condaenv(..., force=TRUE)
    If you prefer to let us automatically install a conda environment with 'mofapy2' installed using the 'basilisk' package, please use the argument 'use_basilisk = TRUE'</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
        #########################################################
        ###           __  __  ____  ______                    ### 
        ###          |  \/  |/ __ \|  ____/\    _             ### 
        ###          | \  / | |  | | |__ /  \ _| |_           ### 
        ###          | |\/| | |  | |  __/ /\ \_   _|          ###
        ###          | |  | | |__| | | / ____ \|_|            ###
        ###          |_|  |_|\____/|_|/_/    \_\              ###
        ###                                                   ### 
        ######################################################### 
       
 
        
use_float32 set to True: replacing float64 arrays by float32 arrays to speed up computations...

Successfully loaded view='mirna' group='group1' with N=150 samples and D=184 features...
Successfully loaded view='mrna' group='group1' with N=150 samples and D=200 features...
Successfully loaded view='protein' group='group1' with N=150 samples and D=142 features...


Model options:
- Automatic Relevance Determination prior on the factors: False
- Automatic Relevance Determination prior on the weights: True
- Spike-and-slab prior on the factors: False
- Spike-and-slab prior on the weights: False
Likelihoods:
- View 0 (mirna): gaussian
- View 1 (mrna): gaussian
- View 2 (protein): gaussian




######################################
## Training the model with seed 42 ##
######################################


ELBO before training: -605349.03 

Iteration 1: time=0.01, ELBO=-97986.53, deltaELBO=507362.501 (83.81321728%), Factors=10
Iteration 2: time=0.01, Factors=10
Iteration 3: time=0.01, Factors=10
Iteration 4: time=0.01, Factors=10
Iteration 5: time=0.01, Factors=10
Iteration 6: time=0.01, ELBO=-85812.38, deltaELBO=12174.149 (2.01109572%), Factors=10
Iteration 7: time=0.01, Factors=10
Iteration 8: time=0.01, Factors=10
Iteration 9: time=0.01, Factors=10
Iteration 10: time=0.01, Factors=10
Iteration 11: time=0.01, ELBO=-85546.36, deltaELBO=266.029 (0.04394630%), Factors=10
Iteration 12: time=0.00, Factors=10
Iteration 13: time=0.01, Factors=10
Iteration 14: time=0.01, Factors=10
Iteration 15: time=0.01, Factors=10
Iteration 16: time=0.01, ELBO=-85119.86, deltaELBO=426.494 (0.07045427%), Factors=10
Iteration 17: time=0.01, Factors=10
Iteration 18: time=0.01, Factors=10
Iteration 19: time=0.01, Factors=10
Iteration 20: time=0.01, Factors=10
Iteration 21: time=0.01, ELBO=-84663.08, deltaELBO=456.782 (0.07545757%), Factors=10
Iteration 22: time=0.01, Factors=10
Iteration 23: time=0.00, Factors=10
Iteration 24: time=0.00, Factors=10
Iteration 25: time=0.00, Factors=10
Iteration 26: time=0.01, ELBO=-84469.19, deltaELBO=193.894 (0.03203003%), Factors=10
Iteration 27: time=0.01, Factors=10
Iteration 28: time=0.01, Factors=10
Iteration 29: time=0.01, Factors=10
Iteration 30: time=0.00, Factors=10
Iteration 31: time=0.01, ELBO=-84312.91, deltaELBO=156.276 (0.02581593%), Factors=10
Iteration 32: time=0.00, Factors=10
Iteration 33: time=0.00, Factors=10
Iteration 34: time=0.00, Factors=10
Iteration 35: time=0.00, Factors=10
Iteration 36: time=0.01, ELBO=-84211.62, deltaELBO=101.293 (0.01673295%), Factors=10
Iteration 37: time=0.00, Factors=10
Iteration 38: time=0.00, Factors=10
Iteration 39: time=0.00, Factors=10
Iteration 40: time=0.00, Factors=10
Iteration 41: time=0.01, ELBO=-84149.57, deltaELBO=62.049 (0.01025015%), Factors=10
Iteration 42: time=0.01, Factors=10
Iteration 43: time=0.00, Factors=10
Iteration 44: time=0.00, Factors=10
Iteration 45: time=0.00, Factors=10
Iteration 46: time=0.01, ELBO=-84113.44, deltaELBO=36.127 (0.00596801%), Factors=10
Iteration 47: time=0.00, Factors=10
Iteration 48: time=0.00, Factors=10
Iteration 49: time=0.00, Factors=10
Iteration 50: time=0.00, Factors=10
Iteration 51: time=0.01, ELBO=-84094.13, deltaELBO=19.309 (0.00318972%), Factors=10
Iteration 52: time=0.00, Factors=10
Iteration 53: time=0.00, Factors=10
Iteration 54: time=0.00, Factors=10
Iteration 55: time=0.00, Factors=10
Iteration 56: time=0.01, ELBO=-84083.06, deltaELBO=11.072 (0.00182895%), Factors=10
Iteration 57: time=0.00, Factors=10
Iteration 58: time=0.00, Factors=10
Iteration 59: time=0.00, Factors=10
Iteration 60: time=0.01, Factors=10
Iteration 61: time=0.01, ELBO=-84075.87, deltaELBO=7.195 (0.00118855%), Factors=10
Iteration 62: time=0.00, Factors=10
Iteration 63: time=0.00, Factors=10
Iteration 64: time=0.00, Factors=10
Iteration 65: time=0.01, Factors=10
Iteration 66: time=0.01, ELBO=-84070.67, deltaELBO=5.196 (0.00085839%), Factors=10
Iteration 67: time=0.01, Factors=10
Iteration 68: time=0.01, Factors=10
Iteration 69: time=0.01, Factors=10
Iteration 70: time=0.01, Factors=10
Iteration 71: time=0.01, ELBO=-84066.69, deltaELBO=3.981 (0.00065768%), Factors=10
Iteration 72: time=0.01, Factors=10
Iteration 73: time=0.01, Factors=10
Iteration 74: time=0.01, Factors=10
Iteration 75: time=0.01, Factors=10
Iteration 76: time=0.01, ELBO=-84063.53, deltaELBO=3.155 (0.00052122%), Factors=10
Iteration 77: time=0.01, Factors=10
Iteration 78: time=0.01, Factors=10
Iteration 79: time=0.01, Factors=10
Iteration 80: time=0.01, Factors=10
Iteration 81: time=0.01, ELBO=-84060.96, deltaELBO=2.577 (0.00042565%), Factors=10
Iteration 82: time=0.01, Factors=10
Iteration 83: time=0.01, Factors=10
Iteration 84: time=0.01, Factors=10
Iteration 85: time=0.01, Factors=10
Iteration 86: time=0.01, ELBO=-84058.83, deltaELBO=2.127 (0.00035130%), Factors=10

Converged!



#######################
## Training finished ##
#######################


Saving model in /var/folders/kh/tgq9mmld6_v9z_h220trj0c40000gn/T//RtmptEmLD6/mofa_20231018-185049.hdf5...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in .quality_control(object, verbose = verbose): Factor(s) 4 are strongly correlated with the total number of expressed features for at least one of your omics. Such factors appear when there are differences in the total 'levels' between your samples, *sometimes* because of poor normalisation in the preprocessing steps.</code></pre>
</div>
</div>
<p>The most important insight that MOFA generates is the variance decomposition analysis. This plot shows the percentage of variance explained by each factor across each data modality.</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-19_340d2d6a85e01541d4dc5aa3eaef0678">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_variance_explained</span>(MOFAobject)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>From the results of the <code>plot_variance_explained</code> function in MOFA, we can discern the variance explained by each factor across the three views: mirna, mrna, and protein.</p>
<p>In the <strong>mirna</strong> view, Factor1 leads by explaining approximately 15.96% of the variance. Notably, Factor1 also stands out in both the <strong>mrna</strong> and <strong>protein</strong> views, explaining 20.37% and 20.41% respectively, suggesting its consistent importance across all views.</p>
<p>For the <strong>mrna</strong> view, besides Factor1, Factor2 contributes significantly with 11.88%. This contrasts with its contribution in the protein view, where it explains only 1.25% of the variance, and in the mirna view, where it accounts for 6.04%.</p>
<p>In the <strong>protein</strong> view, while Factor1 remains dominant, Factor3 emerges as significant, explaining 12.20% of the variance. This is intriguing as Factor3 has a minimal role in the mrna view (0.12%) but does have a presence in the mirna view with 0.65%.</p>
<p>Factors such as Factor4 and Factor7 exhibit diverse roles across the views. In the mirna view, Factor4 explains a notable 12.77% but diminishes to 0.16% and 0.02% in the mrna and protein views respectively. Factor7, on the other hand, is more prominent in the mirna view with 7.09% but is almost negligible in the other two views.</p>
<p><strong>which factor consistently plays a vital role across all views?</strong></p>
<p>Given that Factor1 consistently plays a vital role across all views, we aim to characterize its molecular signal and its association with available sample covariates. Here are the steps we’ll follow:</p>
<p>To understand the relation between Factor1 values and sample metadata, we’ll perform an association analysis.</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-20_7440b5cfe9881fc23c8ecf56e931d964">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">samples_metadata</span>(MOFAobject) <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">sample=</span><span class="fu">colnames</span>(data_mofa<span class="sc">$</span>mirna),<span class="at">subtype=</span>breast.TCGA<span class="sc">$</span>data.train<span class="sc">$</span>subtype)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="fu">correlate_factors_with_covariates</span>(MOFAobject, </span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">covariates =</span> <span class="fu">c</span>(<span class="st">"subtype"</span>), </span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">plot =</span> <span class="st">"log_pval"</span>,<span class="at">cluster_cols=</span>F</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in correlate_factors_with_covariates(MOFAobject, covariates =
c("subtype"), : There are non-numeric values in the covariates data.frame,
converting to numeric...</code></pre>
</div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-20-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This clearly shows a strong association of Factor1 to cancer subtype. The rest of the factors are more or less don’t have a clear association with subtype.</p>
<p>Now that we have a Factor of interest we can plot the values of it. Factors in MOFA are similar to PCA so they are designed to isolate distinct sources of variance present within the data. From a mathematical standpoint, each factor can be described as a linear amalgamation of the provided features. These factors position samples on a one-dimensional scale centered around zero.</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-21_d21071b326c7764f63b7c381c5ea64cb">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizing the factors</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_factors</span>(MOFAobject, </span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">factors =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), </span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">dot_size =</span> <span class="fl">2.5</span>,<span class="at">shape_by =</span> <span class="st">"subtype"</span>,<span class="at">color_by =</span> <span class="st">"subtype"</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-21-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We can see that the pattern in Factor1 has captures the group differences. We should not have a look at the weights for this factor to figure out what are the most important features that contribute to this pattern.</p>
<p>Feature weights play an important role in understanding the influence of each feature on a given factor. These weights offer a quantifiable score for every feature in relation to its respective factor. Essentially, when a feature doesn’t correlate with a factor, its weight is anticipated to hover around zero. Conversely, features that are robustly associated with the factor will display large absolute weight values. The polarity of the weight whether positive or negative reveals the nature of the relationship: a positive weight suggests that the feature level elevates in instances with positive factor values and the opposite for negative weights.</p>
<p>Let’s look athe top 10 features in mRNA.</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-22_6db2d21d7fb836cee2aeea4a5d8f73ca">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_top_weights</span>(MOFAobject,<span class="at">view =</span> <span class="st">"mrna"</span>,</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a> <span class="at">factor =</span> <span class="dv">1</span>,</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a> <span class="at">nfeatures =</span> <span class="dv">10</span>,    </span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a> <span class="at">scale =</span> T          </span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The plot suggest that <code>STC2</code> has a strong <em>negative</em> relationship with Factor1. Looking back at the score plot, we see that our <code>Basal</code> subtype has ended up on the right of the plot, <code>Her2</code> in the middle and <code>LumA</code> on the left. This suggest that the expression of <code>STC2</code> is higher in <code>LumA</code> vs <code>Her2</code> and also <code>Her2</code> vs <code>LumA</code>. Let’s check it:</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-23_23ed1e575a925212ac9a2d6ef7f74388">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_data_scatter</span>(MOFAobject, </span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">view =</span> <span class="st">"mrna"</span>,</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">factor =</span> <span class="dv">1</span>, <span class="at">features =</span> <span class="st">"STC2"</span>,<span class="at">color_by =</span> <span class="st">"subtype"</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-23-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Great. But we have so many other features, do we have a subgroup of features in our data:</p>
<div class="cell" data-hash="mofa_cache/html/unnamed-chunk-24_6ecdd75d6db215128ba51fc831621b73">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>sample_group<span class="ot">&lt;-</span><span class="fu">samples_metadata</span>(MOFAobject)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(sample_group)<span class="ot">&lt;-</span>sample_group[,<span class="dv">1</span>]</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_data_heatmap</span>(MOFAobject, </span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="at">view =</span> <span class="st">"mrna"</span>,</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">factor =</span> <span class="dv">1</span>,  </span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">cluster_rows =</span> <span class="cn">TRUE</span>, <span class="at">cluster_cols =</span> <span class="cn">FALSE</span>,<span class="at">annotation_samples =</span> sample_group[,<span class="st">"subtype"</span>,<span class="at">drop=</span>F],</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">show_rownames =</span> <span class="cn">TRUE</span>, <span class="at">show_colnames =</span> <span class="cn">FALSE</span>,</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">scale =</span> <span class="st">"row"</span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>'annotation_samples' provided as a data.frame, please make sure that the rownames match the sample names</code></pre>
</div>
<div class="cell-output-display">
<p><img src="mofa_files/figure-html/unnamed-chunk-24-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We can at least see two big groups of genes having contrasting expression pattern.</p>
<p><strong>Can you plot the expression of some of genes in each group?</strong></p>
<p>MOFA provies a lot more functionality and visualization tools which are not covered here. For many excellent case-caes, see here: https://biofam.github.io/MOFA2/tutorials.html</p>
<p><strong>Your main task is to perform MOFA on the test data which is in <code>breast.TCGA$data.test</code></strong> 1. Do you see the same pattern as in the training set? 2. Do the top 10 most important features overlap between training and testing? 3. How about the grouping of the features?</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>